<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"sunyrain.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="whilesunny">
<meta property="og:url" content="https://sunyrain.github.io/page/5/index.html">
<meta property="og:site_name" content="whilesunny">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="whilesunny">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://sunyrain.github.io/page/5/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>whilesunny</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">whilesunny</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Sunny&Rainy</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-schedule">

    <a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>日程表</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sunyrain.github.io/2023/09/19/shen-du-xue-xi/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="whilesunny">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="whilesunny">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/09/19/shen-du-xue-xi/" class="post-title-link" itemprop="url">深度学习</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-09-19 09:51:38" itemprop="dateCreated datePublished" datetime="2023-09-19T09:51:38+08:00">2023-09-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-10-23 14:24:50" itemprop="dateModified" datetime="2023-10-23T14:24:50+08:00">2023-10-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AF%BE%E7%A8%8B/" itemprop="url" rel="index"><span itemprop="name">课程</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>正则项目的是减小参数以进一步减少噪声的放大，其并不作用于b上，因为b不与x相乘，不会放大噪声。</p>
<h2 id="Convolutional-Neural-Networks"><a href="#Convolutional-Neural-Networks" class="headerlink" title="Convolutional Neural Networks"></a>Convolutional Neural Networks</h2><h3 id="Convolutional-Layer"><a href="#Convolutional-Layer" class="headerlink" title="Convolutional Layer"></a>Convolutional Layer</h3><ul>
<li>Three shapes of convolution<ul>
<li>valid即全程完整的$f$和$g$进行卷积</li>
<li>full即从一格开始进行卷积</li>
<li>same即通过两侧$f$补零，使得卷积结果和$f$一样长</li>
</ul>
</li>
<li>卷积即$f$与$\tilde{g}$ 的相似度（标准长度）</li>
<li>1-D和2-D都是旋转180°再计算相似度即可</li>
<li>局部链接、权值共享<ul>
<li>举例来说，32*32的</li>
</ul>
</li>
</ul>
<h3 id="Pooling-Layer"><a href="#Pooling-Layer" class="headerlink" title="Pooling Layer"></a>Pooling Layer</h3>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sunyrain.github.io/2023/09/19/ji-qi-xue-xi/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="whilesunny">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="whilesunny">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/09/19/ji-qi-xue-xi/" class="post-title-link" itemprop="url">机器学习</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-09-19 09:51:02" itemprop="dateCreated datePublished" datetime="2023-09-19T09:51:02+08:00">2023-09-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-11-09 15:46:00" itemprop="dateModified" datetime="2023-11-09T15:46:00+08:00">2023-11-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AF%BE%E7%A8%8B/" itemprop="url" rel="index"><span itemprop="name">课程</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="Big-Data-amp-Simple-Model"><a href="#Big-Data-amp-Simple-Model" class="headerlink" title="Big Data &amp; Simple Model"></a>Big Data &amp; Simple Model</h3><p>why machine learning feasible 可行的</p>
<h4 id="Example-pick-red-and-green-marbles-from-a-bin"><a href="#Example-pick-red-and-green-marbles-from-a-bin" class="headerlink" title="Example : pick red and green marbles from a bin"></a>Example : pick red and green marbles from a bin</h4><ul>
<li>$\mathbb{P}[red marbles] &#x3D; \mu \qquad \mathbb{P}[green marbles] &#x3D; 1-\mu$</li>
<li>Hoeffding’s inequality：$P[|\nu-\mu|&gt;\epsilon]\leq2e^{-2\epsilon^2N}$<ul>
<li>其中$\nu$  是取样中红色球的比例  </li>
<li>可见实验结果误差大于$\epsilon$的概率并不取决于期望，而取决于实验的次数$N$</li>
<li>该例子具有一定的特殊性，因为其为Brenoulli实验，且所考虑的$\nu$和$\mu$均在0到1之间</li>
<li>关键：big data gives an accurate learning result</li>
</ul>
</li>
<li>广义Hoeffding’s inequality：$$\mathbb{P}\left(\left|S_n-\mathbb{E}\left[S_n\right]\right| \geq t\right) \leq 2 \exp \left(-\frac{2 t^2}{\sum_{i&#x3D;1}^n\left(b_i-a_i\right)^2}\right)<br>\tag{1}$$<ul>
<li>$b_i ,a_i$分别为变量$X_i$的上限和下限</li>
<li>注意到$S_n$是变量之和，如果要与伯努利情况下的Koeffding比较，则可以考虑指数上下同除$n^2$</li>
<li>在广义的情况下考虑本例，$b_i-a_i&#x3D;1$，代入即得本例情况</li>
</ul>
</li>
</ul>
<h4 id="Example-拓展"><a href="#Example-拓展" class="headerlink" title="Example 拓展"></a>Example 拓展</h4><ul>
<li>将未知的$\mu$替换为$f(x)$，我们给出假设$h(x)$，从取球的角度来看，每一次取球，就相当于在定义域$X$中取一个$x$，取出红球意味着，$h(x)\ne f(x)$，而取出绿球则意味着$h(x) &#x3D; f(x)$ </li>
<li>在上述前提下，定义$E_{in}(h)$作为抽样错误率，也即“in sample error”，同时定义$E_{out}(h)$作为总错误率，也即对所有利用假设进行判断后$h(x) \ne f(x)$ 的比率。其实也就是之前所述的$\nu$和$\mu$，我们想要知道我们的假设$h$效果怎么样，但是没必要把所有$x$全带入。</li>
<li>$h$的参数空间记为$H$ ，其中最优的假设是$g$，经过训练后，$g$会尽可能接近$f$ </li>
<li>$$\mathbb{P}\left[\left|E_{\text {in }}(g)-E_{\text {out }}(g)\right|&gt;\epsilon\right] \leq \sum_{m&#x3D;1}^M \mathbb{P}\left[\left|E_{\text {in }}\left(h_m\right)-E_{\text {out }}\left(h_m\right)\right|&gt;\epsilon\right]$$</li>
<li>$$\mathbb{P}\left[\left|E_{\text {in }}(g)-E_{\text {out }}(g)\right|&gt;\epsilon\right] \leq 2 M e^{-2 \epsilon^2 N}<br>\tag{2}$$</li>
<li>这条式子的意思是，给出所有$M$个假设中，最优的一个，训练集和实际集的误差上限（这本身不能让$g$接近$f$）这很好理解，因为右侧包含左侧。<blockquote>
<p>Low complexity model and big data can give us a good generalization in machine learning</p>
</blockquote>
</li>
</ul>
<h3 id="Supervised-learning"><a href="#Supervised-learning" class="headerlink" title="Supervised learning"></a>Supervised learning</h3><blockquote>
<p>Use labelled dataset to train algorithms</p>
</blockquote>
<h4 id="Regression-Ⅰ"><a href="#Regression-Ⅰ" class="headerlink" title="Regression Ⅰ"></a>Regression Ⅰ</h4><ul>
<li>Linear Regression<ul>
<li>$y_{i}&#x3D;f_{\beta_{0},\beta_{1}}(x_{i})+\epsilon_{i}&#x3D;\beta_{0}+x_{i}\beta_{1}+\epsilon_{i}\quad$其中$\epsilon$即为残差<ul>
<li>$f_{\beta_{0},\beta_{1}}$是线性回归的函数，训练目标是最小化$\epsilon$的平方和</li>
</ul>
</li>
<li>Cost Function<ul>
<li>$C\left(\beta_0,\beta_1\right)&#x3D;\sum_{i&#x3D;1}^m\left(y_i-f_{\beta_0,\beta_1}\left(x_i\right)\right)^2$</li>
</ul>
</li>
<li>Assumptions<ul>
<li>Weak exogeneity 假设残差的期望为0</li>
<li>Linearity 假设WX+b&#x3D;y</li>
<li>Homoscedasticity 假设因变量方差不随自变量改变<ul>
<li>假设我们通过房子的面积等预测房价，我们可以假设不管面积是大是小，价格的方差不会变。而事实上也存在反例，例如我们一般认为，小房子的价格波动更大</li>
</ul>
</li>
</ul>
</li>
<li>Ordinary least squares<ul>
<li>Cost Function $(y_{i}-f_{\beta_{0},\beta_{1}}(x_{i}))^2$ </li>
<li>对两个参数分别求偏导及二阶偏导，最小化损失函数</li>
<li>Coefficient of determination $r^2$<ul>
<li>$$r^2&#x3D;1-\frac{\sum_{i&#x3D;1}^m\left(y_i-f_{\beta_0, \beta_1}\left(x_i\right)\right)^2}{\sum_{i&#x3D;1}^m\left(y_i-\bar{y}\right)^2} \times 100 % \tag{3}$$</li>
<li>也即比较线性回归模型残差平方和和原有数据残差平方和（相对于$\bar{y}$）故$r^2$越大越优</li>
<li>定性看一下，直接拿均值肯定很烂，然后$r^2&#x3D;1$的话，说明完全拟合上了</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Multiple Linear Regression<ul>
<li>额外假设，不存在多重共线性</li>
<li>同样思路，计算一阶导数并令之为0</li>
<li>$$\begin{gathered}C(\boldsymbol{\beta})&#x3D;(\boldsymbol{y}-X \boldsymbol{\beta})^T(\boldsymbol{y}-X \boldsymbol{\beta})&#x3D;\boldsymbol{y}^T \boldsymbol{y}+\boldsymbol{\beta}^T X^T X \boldsymbol{\beta}-2 \boldsymbol{\beta}^T X^T \boldsymbol{y} \\frac{\partial C(\boldsymbol{\beta})}{\partial \boldsymbol{\beta}}&#x3D;2 X^T X \boldsymbol{\beta}-2 X^T \boldsymbol{y}\end{gathered}$$</li>
<li>据此给出 $\widehat{\boldsymbol{\beta}}$的表达式</li>
<li>$$\widehat{\boldsymbol{\beta}}&#x3D;\left(X^T X\right)^{-1} X^T \boldsymbol{y}$$</li>
<li>计算二阶导数</li>
<li>$$\mathcal{H}&#x3D;\frac{\partial^2 C(\boldsymbol{\beta})}{\partial \boldsymbol{\beta}^2}&#x3D;2 X^T X$$</li>
<li>证明海森矩阵正定（$a$是任意给定非零向量）</li>
<li>$$\boldsymbol{a}^T X^T X \boldsymbol{a}&#x3D;(X \boldsymbol{a})^T X \boldsymbol{a}&#x3D;|X \boldsymbol{a}|_2^2 \geq 0$$</li>
<li>定义hat matrix</li>
<li>$$\widehat{\boldsymbol{y}}&#x3D;X \widehat{\boldsymbol{\beta}}&#x3D;X\left(X^T X\right)^{-1} X^T \boldsymbol{y}&#x3D;X\left(X^T X\right)^{-\mathbf{1}} X^T \boldsymbol{y}&#x3D;H \boldsymbol{y}$$</li>
<li>Properties of hat matrix<ul>
<li>$H$ 、$I-H$  均是正交投影矩阵</li>
<li>Idempotent $H&#x3D;H^2$、$(I-H)&#x3D;(I-H)^2$</li>
<li>残差由$\epsilon&#x3D;y-\hat{y}&#x3D;y-Hy&#x3D;(I-H)y$给出<ul>
<li>当然，残差的平方和$\epsilon^T \epsilon&#x3D;y^T(I-H)y$（依据幂等消掉了一个）</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Maximum Likelihood Estimation<ul>
<li>Assumptions<ul>
<li>随机取样残差符合均值为0的高斯分布，在残差为0时，概率取最大值<ul>
<li>在假设残差符合高斯分布的前提下，假设其方差为$\sigma^2$</li>
</ul>
</li>
<li>$$p\left(\left(\boldsymbol{x}_{\boldsymbol{i}}, y_i\right) \mid \boldsymbol{\beta}\right)&#x3D;\frac{1}{\sqrt{2 \pi \sigma^2}} e^{-\frac{\left(y_i-\boldsymbol{\beta}^T x_i\right)^2}{2 \sigma^2}}$$</li>
<li>复习的时候发现这里非常容易混淆，再次强调$p((x_i,y_i)|\beta)$其实指的是$x_i$在参数为$\beta$时给出的预测和真实的标签$y_i$的差距服从的分布</li>
<li>依据常规高斯分布公式分析，其实就是下式（对于残差，均值$\mu$为0）</li>
<li>$$p;(\left(\epsilon_i) \mid \boldsymbol{\beta}\right)&#x3D;\frac{1}{\sqrt{2 \pi \sigma^2}} e^{-\frac{(\epsilon_i-0)^2}{2 \sigma^2}}$$</li>
<li>$(x_i,y_i)$独立同分布</li>
</ul>
</li>
<li>最大似然估计最大化在所有取样点处的概率之和，这样约等于最小化残差</li>
<li>最大化以下式子：$$p\left(D \mid \boldsymbol{\beta}, \sigma^2\right)&#x3D;p\left(\left(\boldsymbol{x}<em>{\mathbf{1}}, y_1\right), \ldots\left(\boldsymbol{x}</em>{\boldsymbol{m}}, y_m\right) \mid \boldsymbol{\beta}, \sigma^2\right)$$</li>
<li>Calculate the expression of likelihood</li>
<li>Due to the assumption of independency$$p\left(\left(\boldsymbol{x}<em>1, y_1\right), \ldots\left(\boldsymbol{x}</em>{\boldsymbol{m}}, y_m\right) \mid \boldsymbol{\beta}, \sigma^2\right)&#x3D;\prod_{i&#x3D;1}^m p\left(\left(\boldsymbol{x}_{\boldsymbol{i}}, y_i\right) \mid \boldsymbol{\beta}, \sigma^2\right)$$</li>
<li>Due to the assumption of Gaussian Distribution$$\prod_{i&#x3D;1}^m p\left(\left(\boldsymbol{x}<em>{\boldsymbol{i}}, y_i\right) \mid \boldsymbol{\beta}, \sigma^2\right)&#x3D;\prod</em>{i&#x3D;1}^m \frac{1}{\sqrt{2 \pi \sigma^2}} e^{-\frac{\left(y_i-\boldsymbol{\beta}^T \boldsymbol{x}_i\right)^2}{2 \sigma^2}}$$</li>
<li>Due to the assumption of homoscedasticity$$\prod_{i&#x3D;1}^m \frac{1}{\sqrt{2 \pi \sigma^2}} e^{-\frac{\left(y_i-\boldsymbol{\beta}^T x_i\right)^2}{2 \sigma^2}}&#x3D;\left(\frac{1}{\sqrt{2 \pi \sigma^2}}\right)^m e^{-\frac{\sum_{i&#x3D;1}^m\left(y_i-\boldsymbol{\beta}^T x_i\right)^2}{2 \sigma^2}}$$</li>
<li>Calculate the Log-likelihood$$\mathcal{L}\left(\boldsymbol{\beta}, \sigma^2\right)&#x3D;-\frac{m}{2} \ln \left(2 \pi \sigma^2\right)-\frac{1}{2 \sigma^2}(\boldsymbol{y}-X \boldsymbol{\beta})^T(\boldsymbol{y}-X \boldsymbol{\beta})$$</li>
<li>到此步为止，为了最大化似然，需要最小化$\frac{m}{2} \ln \left(2 \pi \sigma^2\right)+\frac{1}{2 \sigma^2}(\boldsymbol{y}-X \boldsymbol{\beta})^T(\boldsymbol{y}-X \boldsymbol{\beta})$ 也即最小化$(\boldsymbol{y}-X \boldsymbol{\beta})^T(\boldsymbol{y}-X \boldsymbol{\beta})\quad$这与多元线性回归类似（最小化残差平方和）</li>
<li>分别对$\beta$和$\sigma^2$求偏导，注意得到的$\sigma$是残差的标准差，又由于同分布假设，故假设最后的结果是$y_{predict}$则95%置信区间为$y_{predict}\pm 1.96\sigma$</li>
</ul>
</li>
</ul>
<h2 id="Gradient-Descent-Ⅰ"><a href="#Gradient-Descent-Ⅰ" class="headerlink" title="Gradient Descent Ⅰ"></a>Gradient Descent Ⅰ</h2><h3 id="Illustration-1D"><a href="#Illustration-1D" class="headerlink" title="Illustration(1D)"></a>Illustration(1D)</h3><p>对于1-D线性回归模型，我们可以发现，损失函数是一个下凸函数，所以我们可以先随机选定一组参数$(\beta_0,\beta_1)$ 相当于在碗的壁上放了一个乒乓球，之后按以下策略，迭代参数$(\beta_0,\beta_1)$<br>$$<br>\begin{gathered}<br>\beta_1^{(i+1)}&#x3D;\beta_1^{(i)}-\alpha \frac{\partial C\left(\beta_0^{(i)}, \beta_1^{(i)}\right)}{\partial \beta_1}&#x3D;\beta_1^{(i)}+2 \alpha \sum_{i&#x3D;1}^m\left(y_i-\beta_1^{(i)} x_i-\beta_0^{(i)}\right) x_i \<br>\beta_0^{(i+1)}&#x3D;\beta_0^{(i)}-\alpha \frac{\partial C\left(\beta_0^{(i)}, \beta_1^{(i)}\right)}{\partial \beta_0}&#x3D;\beta_0^{(i)}+2 \alpha \sum_{i&#x3D;1}^m\left(y_i-\beta_1^{(i)} x_i-\beta_0^{(i)}\right)<br>\end{gathered}<br>$$</p>
<ul>
<li>注意到有 $C\left(\beta_0,\beta_1\right)&#x3D;\sum_{i&#x3D;1}^m\left(y_i-f_{\beta_0,\beta_1}\left(x_i\right)\right)^2$</li>
<li>注意区分在优化问题中的参数$x$以及具体的数据点$x$两者容易搞混</li>
</ul>
<blockquote>
<p>第一讲到此结束</p>
</blockquote>
<hr>
<h2 id="Gradient-Descent-Ⅱ"><a href="#Gradient-Descent-Ⅱ" class="headerlink" title="Gradient Descent Ⅱ"></a>Gradient Descent Ⅱ</h2><blockquote>
<p>For General functions, the gradient descent algorithm is often stuck at a local minimum</p>
</blockquote>
<ul>
<li>数值方法求解梯度<ul>
<li>$\partial f&#x2F; \partial x &#x3D; (f(x+\epsilon)-f(x))&#x2F;\epsilon$</li>
</ul>
</li>
<li>Line search<ul>
<li>Exact Line Search<ul>
<li>$a_i^{*} &#x3D; argmin_{a_i&gt;&#x3D;0}f(x_i+a_i\Delta x_i)$</li>
<li>在一定范围内搜索$\alpha$让$f$最小</li>
<li>问题在于操作繁琐计算需求大，主要是为了找一个让函数沿着当前方向下降最大的步长</li>
</ul>
</li>
<li>Backtracking Search<ul>
<li>核心思想是“你至少下降这么多我才可以接受”，核心目标是确定一个还算不错的步长</li>
<li>设置一个值$\gamma$衡量所期望的函数下降的程度，同时设置一个值$\rho$ 来逐步缩小步长直到符合要求</li>
<li>目标是比较$f(x+\alpha \Delta x)$与$f(x)+\alpha \gamma \nabla f(x)^T \Delta x$，如果当前选择的步长未能使函数下降至小于期望，则将步长$\alpha$缩小为$\rho \alpha$ </li>
<li>$Wolfe ; 1^{st} ; and ; Wolfe ; 2^{nd} ; condition$<ul>
<li>第一条件，也就是在回溯线搜索中用到的条件，限制步长不要太长，以至于错过local minimum</li>
<li>第二条件，约束 $\frac{\phi^{\prime}(a)}{\phi^{\prime}(0)}&#x3D;\frac{\nabla f(x+a\Delta x)^{T}\Delta x}{\nabla f(x)^{T}\Delta x}\leq \eta$也即要求新的位置的斜率必须相较最初变得一定程度上平缓，这使得了步长不会过短<ul>
<li>注意到如果原地不动$\eta&#x3D;1$，如果移动至局部最小值，$\eta &#x3D; 0$所以一般取$\eta$在0到1之间</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Newton’s method<ul>
<li>牛顿法本用来通过数值方法找到函数根的近似解，但也可以稍加变化使之可以应用在梯度下降法中，即将求根的对象从$f$变为$f^{‘}$  </li>
<li>公式可写作$x_{i+1}&#x3D;x_{i}-\frac{f’(x_{i})}{f’’(x_{i})}$</li>
<li>在一维情况下阐述工作原理<ul>
<li>首先我们在某点计算目标函数的梯度和Hessian，之后用这些信息形成二阶泰勒展开，得到二次曲线</li>
<li>之后我们找到二次曲线的最小值位置，更新$x_{k+1}$</li>
<li>参考公式如下$f(x)\approx f(x_{i})+\boldsymbol{g}^{T}(x-\boldsymbol{x}<em>{i})+\frac{1}{2}(\boldsymbol{x}-\boldsymbol{x}</em>{i})^{T}H(\boldsymbol{x}-\boldsymbol{x}_{i})$ </li>
<li>一张很有启发意义的图</li>
<li>![[Pasted image 20231102110212.png]]</li>
<li>伪代码可以理解为$x_{i+1} &#x3D; x_i -H^{-1}g$</li>
<li>补充说明<ul>
<li>如果H并不是正定的，有两种方法解决此问题<ul>
<li>采用Dk矩阵替换$H^{-1}$对角元素，具体表达式如下$D_{k}(i,i)&#x3D;\max\left(\varepsilon,\frac{\partial f^{2}}{\partial x_{i}^{2}}\right)^{-1}$ </li>
<li>或采用LMA，在Hessian非正定的情况下，退化为gradient descent</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Stochastic gradient descent<ul>
<li>在大数据量的背景下，很难利用所有数据计算Cost Function</li>
<li>解决方案：Stochasitically sample from the dataset.</li>
<li>对比Linear regression背景下，GD和SGD的区别与联系<ul>
<li>GD略，见前</li>
<li>SGD的Cost Function只对一个点计算，每计算一个点就更新所有参数权重，一般对全数据做1到10次扫描，假设数据量为m则，则一轮扫描就对参数进行了m次更新，而GD此时只进行了一次更新</li>
<li>优势：快</li>
<li>劣势<ul>
<li>失去了向量化的优势，现代的硬件，例如CPU或者GPU对向量化运算进行了优化，能够同时对数组或向量的多个元素执行相同的操作，从而大大提高运算效率，但是SGD舍弃了这种优势</li>
<li>不是所有的迭代都朝向最优方向</li>
<li>收敛速度较慢，在最优解附近可能会发生震荡等<ul>
<li>解决方案，调整学习率为$\frac{C_1}{i+C_2}$，其中$C_1,C_2$均常数，$i$为迭代次数，这可以使得学习率逐渐下降，最终在最优解附近波动较小</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Mini-batch<ul>
<li>原理和思路类似SGD，但是不是取单一点而是取一组k个点，提高了稳定性，同时也保证了相对较快的速度和较小的计算资源消耗</li>
</ul>
</li>
<li>Momentum method<ul>
<li>提出的根本原因是一般的梯度下降由于震荡问题不能引入太大的$\alpha$，而且不具有记忆</li>
<li>对比一般梯度下降和动量梯度下降<ul>
<li>一般梯度下降$x^{(i+1)}&#x3D;x^{(i)}-\alpha\nabla f(x^{(i)})$</li>
<li>而动量梯度下降表达式为：<ul>
<li>$\boldsymbol{x}^{(i+1)}&#x3D;\boldsymbol{x}^{(i)}+\boldsymbol{v}^{(i)}$</li>
<li>$\boldsymbol{v}^{(i)}&#x3D;-\alpha\nabla f\big(\boldsymbol{x}^{(i)}\big)+\boldsymbol{\theta}\boldsymbol{v}^{(i-1)}$</li>
</ul>
</li>
<li>动量梯度下降利用速度项更新$x$，而速度项$v$和梯度以及上一时刻的速度$v_{i-1}$有关，相当于保有了“记忆”</li>
<li>事实上$v_i&#x3D;-\alpha\sum_{k&#x3D;0}^{i}\theta^{k}\nabla f(x^{(i-k)})$ 对之前的的速度进行了指数衰减级的记忆</li>
</ul>
</li>
<li>补充知识：条件数Condition Number<ul>
<li>定义，$k&#x3D;(\frac{a}{b})^2$</li>
<li>一般GD $O(klog(\frac{1}{\epsilon}))$</li>
<li>一般SGD $O(\sqrt{k}log(\frac{1}{\epsilon}))$</li>
</ul>
</li>
</ul>
</li>
<li>Nesterov’s accelerated<ul>
<li>尝试解决动量梯度下降存在的，在局部最优点可能具有较大速度导致错过最优点的现象</li>
<li>原理是通过在速度项中的梯度项中，将原来的参数空间$x_i$改为“下一步的位置”，也即$x_i\theta v_{i-1}$，起到了“看前一步”的效果</li>
</ul>
</li>
<li>AdaGrad&#x2F;RMSprop<ul>
<li>AdaGrad允许学习率随着参数调整，他的宗旨是，对于梯度大的参数，我们适当减小学习率，对于梯度小的参数，我们维护一个较大的学习率<ul>
<li>$x_j^{(i+1)}&#x3D;x_j^{(i)}-\frac{\alpha}{\sqrt{g_j^{(i)}+\epsilon}}\Delta x_j^{(i)}$ </li>
<li>$g_{j}^{(i)}&#x3D;g_{j}^{(i-1)}+\left(\Delta x_{j}^{(i)}\right)^{2}$</li>
<li>这里的$g_j$维护的是该参数的历史梯度平方和，一定程度上可以反映该参数的历史梯度情况</li>
</ul>
</li>
<li>RMSprop与AdaGrad逻辑相似，但是对于历史梯度的记忆是随时间衰减的<ul>
<li>$x_{j}^{(i+1)}&#x3D;x_{j}^{(i)}-\frac{\alpha}{\sqrt{l_{j}^{(i)}}+\epsilon}\Delta x_{j}^{(i)}$ </li>
<li>$l_{j}^{(i)}&#x3D;(1-\varphi)l_{j}^{(i-1)}+\varphi\left(\Delta x_{j}^{(i)}\right)^{2}$ </li>
<li>其中$l_j$保留了梯度平方历史的加权和，并按某参数衰减，类似Momentum GD对于历史速度的处理方法</li>
</ul>
</li>
</ul>
</li>
<li>Adam(Momentum&amp;RMSprop) Nadam(Nesterov’s accelerated&amp;RMSprop)</li>
</ul>
<h3 id="Induction-amp-Deduction"><a href="#Induction-amp-Deduction" class="headerlink" title="Induction &amp; Deduction"></a>Induction &amp; Deduction</h3><h2 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h2><ul>
<li>Ridge Regression<ul>
<li><p>在线性回归模型中，较大的参数往往会让模型变得更为敏感，我们一般添加一些正则化项惩罚$w$项的长度</p>
</li>
<li><p>一个添加了$L2$正则化处罚项的损失函数一般类似于</p>
</li>
<li><p>$$C(\boldsymbol{w})&#x3D;\frac{1}{2}\sum_{n&#x3D;1}^{N}\left(\boldsymbol{x}<em>{n}^{T}\boldsymbol{w}-y</em>{n}\right)^{2}+\frac{\lambda}{2}|w|_{2}^{2}&#x3D;\frac{1}{2}(X\boldsymbol{w}-\boldsymbol{y})^{T}(X\boldsymbol{w}-\boldsymbol{y})+\frac{\lambda}{2}w^{T}\boldsymbol{w}$$</p>
</li>
<li><p>当然，梯度也要随之更改：</p>
</li>
<li><p>$$\nabla C(\mathbf{w})&#x3D;\nabla\left{\frac{1}{2}(X\mathbf{w}-\mathbf{y})^{T}(X\mathbf{w}-\mathbf{y})+\frac{\lambda}{2}\mathbf{w}^{T}\mathbf{w}\right}&#x3D;0$$</p>
</li>
<li><p>解得：$\boldsymbol{w}^*&#x3D;(X^TX+\lambda I)^{-1}X^T\boldsymbol{y}$</p>
<ul>
<li>这个解是符合逻辑的，如果去除正则项，则为$\boldsymbol{w}^*&#x3D;(X^TX)^{-1}X^T\boldsymbol{y}$</li>
</ul>
</li>
<li><p>应用了正则化以后，training loss会变差，这是自然的，因为引入了新的损失项目，导致模型更难过拟合以下降training loss</p>
</li>
<li><p>必须指出当$\lambda$上升时，会导致函数趋近于$f(x)&#x3D;0$以减少惩罚</p>
</li>
<li><p>但是不会将任何系数压缩到0，而是将它们都逼近0，会在模型中保留所有特征，尽管有些值会很小</p>
</li>
</ul>
</li>
<li>Lasso回归<ul>
<li>与岭回归不同的是，Lasso回归采用L1正则项</li>
<li>$$C(\boldsymbol{w})&#x3D;{\frac12}\sum_{n&#x3D;1}^N(x_n^T\boldsymbol{w}-y_n)^2+{\frac\lambda2}|w|$$</li>
<li>Lasso可以实现特征选择，参考下图，蓝绿色区域是正则化误差，而红线是平方误差等高线，Lasso在坐标轴上取得了理想的解，一个特征因此被舍弃了</li>
<li>![[Pasted image 20231104102253.png]]</li>
<li>也可以这样比较</li>
<li>![[Pasted image 20231104103346.png]]</li>
<li>可以发现随着$\lambda$的增大，Lasso回归的x轴系数最终变为0</li>
</ul>
</li>
<li>Elastic-net regression（弹性网络回归）<ul>
<li>实际上就是将Lasso和Rigid结合</li>
<li>$$\frac{1}{2}\sum_{n&#x3D;1}^{N}\bigl(x_{n}^{T}w-y_{n}\bigr)^{2}+\frac{\lambda_{1}}{2}|w|+\frac{\lambda_{2}}{2}|w|_{2}^{2}$$<blockquote>
<p>相关性并不意味着因果性，使用回归技术并不意味着特征与标签有因果关系</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h2 id="Supervised-learning-1"><a href="#Supervised-learning-1" class="headerlink" title="Supervised learning"></a>Supervised learning</h2><h3 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h3><ul>
<li>Logistic regression<ul>
<li>即训练一组参数W、b，使得WX+b带入sigmoid函数可以区分是两类中的哪一类。一般使用梯度上升，最大化似然函数</li>
<li>Sigmoid function<ul>
<li>$$g(z)&#x3D;\frac{1}{1+e^{-z}}$$</li>
<li>Property Ⅰ  $g^{‘}(z)&#x3D; g(z)(1-g(z))$</li>
<li>Property Ⅱ  $1-g(z)&#x3D;g(-z)$</li>
</ul>
</li>
<li>Maximum likelihood estimation<ul>
<li>其实就是在给定参数$\beta$下，数据点$x_i$观察到$y_i$标签的概率，严格来说应该是给定$\beta$在给定$x_i$模型返回$y_i$的概率</li>
<li>不妨假设$y_i$服从伯努利分布，则$m$条数据的概率表达式为</li>
<li>$$\prod_{i&#x3D;1}^{m}p((x_{i},y_{i})|\boldsymbol{\beta})&#x3D;\prod_{i&#x3D;1}^{m}f_{\boldsymbol{\beta}}(x_{i})^{\nu_{i}}(1-f_{\boldsymbol{\beta}}(x_{i}))^{1-\nu_{i}}$$<ul>
<li>注记一下，这里假设$y_i$有0和1两种可能，所以直接放在指数上了</li>
</ul>
</li>
<li>综上，最大似然函数的对数是</li>
<li>$$\mathcal{L}(\boldsymbol{\beta})&#x3D;\log\left(\prod_{i&#x3D;1}^mp((\boldsymbol{x}<em>i,y_i)|\boldsymbol{\beta})\right)&#x3D;\sum</em>{i&#x3D;1}^my_i\log\left(f_\beta(x_i)\right)+(1-y_i)\log\left(1-f_\beta(x_i)\right)$$<ul>
<li>我们的目标就是找到这样一个$\beta$使得$\mathcal{L}(\beta)$最大<ul>
<li>其实也就是提高全部预测准确的概率</li>
</ul>
</li>
<li>在我们使用了$sigmoid$函数的前提下，公式又可以如下转化</li>
<li>$$\boldsymbol{\beta}^{*}&#x3D;\underset{\boldsymbol{\beta}}{\mathrm{argmax}}\sum_{i&#x3D;1}^{m}y_{i}\log\Big(g(\boldsymbol{\beta}^{T}x_{i})\Big)+(1-y_{i})\mathrm{log}\Big(1-g\big(\boldsymbol{\beta}^{T}x_{i}\big)\Big)$$</li>
<li>如果我们应用SGD求解，则最终的更新公式为</li>
<li>$$\left.\beta^{(k+1)}&#x3D;\beta^{(k)}+\alpha\left[y_i-g\left(\beta^{(k)}\right.^Tx_i\right)\right]x_i$$</li>
<li>Logistic regression的评价标准<ul>
<li>$$\frac{number, of, correctly, classified, }{number, of, total, training, data}$$</li>
<li>或者采用Efron’s</li>
<li>$$r^{2}&#x3D;1-\frac{\sum_{i&#x3D;1}^{m}(f(x_{i})-y_{i})^{2}}{\sum_{i&#x3D;1}^{m}(y_{i}-\bar{y})^{2}}$$</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Multi-classes多分类问题<ul>
<li>Softmax<ul>
<li>公式如下</li>
<li>$$\mathrm{P}(y|\theta)&#x3D;\mathrm{P}(y|x,{\boldsymbol{\beta}<em>{k}}</em>{k&#x3D;1}^{K})&#x3D;\prod_{k&#x3D;1}^{K}\left(\frac{\exp{\boldsymbol{x}^{T}\boldsymbol{\beta}<em>{k}}}{\sum</em>{k^{\prime}&#x3D;1}^{K}\exp{\boldsymbol{x}^{T}\boldsymbol{\beta}<em>{k^{\prime}}}}\right)^{y</em>{k}}$$</li>
<li>注：对需要划分的每一个类训练一组参数（注意和深度学习区别，深度学习中一般在网络结构的最后一层统一使用softmax，并不会为每一类单独训练参数）</li>
<li>注：$y$是一个标签向量，一般采用了独热编码，例如在五分类问题中表示为$（0，0，1，0，0）$ 这一般表示为第三类。等式表示在给定k组参数和$x$的前提下，对某条数据预测正确的概率</li>
<li>注：以标签作为指数，其实就是取出了独热编码中$y_k$&#x3D;1的概率，只是形式上更为统一</li>
<li>综上，我们可以给出Log loss function</li>
<li>$$\log\prod_{i&#x3D;1}^{m}\mathrm{P}(\mathbf{y}<em>{i}|\mathbf{x}</em>{i},{\boldsymbol{\beta}<em>{k}}</em>{k&#x3D;1}^{K})&#x3D;\log\left[\prod_{i&#x3D;1}^{m}\prod_{k&#x3D;1}^{K}\left(\frac{\exp(\boldsymbol{x}<em>{i}^{T}\boldsymbol{\beta}</em>{k})}{\sum_{k^{\prime}&#x3D;1}^{K}\exp(\boldsymbol{x}<em>{i}^{T}\boldsymbol{\beta}</em>{k^{\prime}})}\right)^{y_{i,k}}\right]$$</li>
<li>以及其对每组参数的梯度</li>
<li>$$&#x3D;\sum_{i&#x3D;1}^{m}[y_{i,k}-\theta_{k}]x_{i}$$</li>
</ul>
</li>
<li>concave(上凸的)、convex(下凸的)</li>
<li>Prceptron<ul>
<li>通过多层感知机可以实现数据区域的分割</li>
<li>本质上来讲，单层感知机可以视作一个线性分类器，把空间按照一定的规则划分为两半</li>
<li>$$f_{A}(x)&#x3D;\mathrm{sgn}\left(\sum_{i&#x3D;0}^{d}\beta_{i}x_{i}\right)&#x3D;\mathrm{sgn}(\beta^{T}x)$$</li>
</ul>
</li>
</ul>
</li>
<li>GDA高斯判别分析<ul>
<li>与一般的Discriminative learning算法不同，GDA尝试学习$p(x|y)(and ; p(y))$ ,之后利用其去构建后验分布</li>
<li>整体来说，分类问题的目标是求$argmax_y;p(y|x)$这一点是不变的，但是GDA做了如下转化</li>
<li>$$\begin{aligned}\operatorname{argmax}_yp(y|x)&#x3D;\operatorname{argmax}_y\frac{p(x|y)p(y)}{p(x)}&#x3D;\operatorname{argmax}_yp(x|y)p(y)\end{aligned}$$</li>
<li>所以我们可以转为计算$p(y)$和$p(x|y)$，然后对他们的乘积找一个$y$使其最大化，下分别计算之</li>
<li>$p(y)&#x3D;\phi^{1{y&#x3D;\times}}(1-\phi)^{1-1{y&#x3D;\times}}$</li>
<li>$p(\boldsymbol{x}|y&#x3D;\times)&#x3D;\frac{1}{(2\pi)^{d&#x2F;2}|\Sigma|^{1&#x2F;2}}\exp\left(-\frac{1}{2}(\boldsymbol{x}-\boldsymbol{\mu}_\times)^T\Sigma^{-1}(\boldsymbol{x}-\boldsymbol{\mu}_\times)\right)$</li>
<li>$p(x|y&#x3D;{0})&#x3D;\frac1{(2\pi)^{d&#x2F;2}|\Sigma|^{1&#x2F;2}}\exp\left(-\frac12(x-\mu_0)^T\Sigma^{-1}(x-\mu_0)\right)$</li>
<li>$\Sigma^T&#x3D;\frac1m\Sigma_{i&#x3D;1}^m\left(x^{(i)}-\mu_{y^{(i)}}\right)\left(x^{(i)}-\mu_{y^{(i)}}\right)^T$</li>
<li>$\phi&#x3D;\frac1m\sum_{i&#x3D;1}^m1{y^{(i)}&#x3D;\times}$</li>
</ul>
</li>
</ul>
<h4 id="Decision-Tree"><a href="#Decision-Tree" class="headerlink" title="Decision Tree"></a>Decision Tree</h4><ul>
<li>Logistic Regression只有在数据本身分布比较理想，具有明确的界限时，效果才会比较良好</li>
<li>决策树<ul>
<li>连通无环结构</li>
<li>树的节点表示属性测试</li>
<li>叶节点表示分类结果</li>
<li>每一次划分其实是对空间进行一次轴对齐的超平面划分，树可以向图转换，图也可以还原成树</li>
</ul>
</li>
<li>决策树的建立<ul>
<li>建立最小决策树是NP问题，我们使用贪心算法作为一个较好的近似模型<ul>
<li>首先我们从空的决策树开始</li>
<li>选择最优特征，同时选择最优的特征阈值</li>
<li>在划分出来的新节点上继续上述循环，直到到达终止条件</li>
</ul>
</li>
<li>所以重点就是“Splitting Criteria”</li>
</ul>
</li>
<li>$Classification; Error$（可以用来评价划分的质量）<ul>
<li>$Error(i|j,t_{j}) &#x3D; 1-\max <em>{k}P(k|R</em>{i})$ </li>
<li>注意这里P不是概率，而是$R_i$中k的比例，比方说一个完美的分类，$R_i$中只有k，那么$Error$就是0</li>
<li>其中，$j$是划分的维度，$t_j$是划分的阈值</li>
<li>树当前的每一个叶子节点都代表了一块区域，而算法的继续进行需要做的，就是将该空间继续划分成两块</li>
<li>$\min _{j, t_j}\left{\frac{N_1}{N} \operatorname{Error}\left(1 \mid j, t_j\right)+\frac{N_2}{N} \operatorname{Error}\left(2 \mid j, t_j\right)\right}$<ul>
<li>区域被划分为两块，分别是$R_1$和$R_2$，将两块区域的误差加权相加即得到需要最小化的误差函数</li>
</ul>
</li>
</ul>
</li>
<li>我们也可以使用$Gini;index$ <ul>
<li>通过测试每个区域的”纯度”，来判断划分质量</li>
<li>$Gini(i|j,t_j)&#x3D;1-\Sigma_k P(k|R_i)^2$</li>
<li>再次提醒，$P(k|R_i)$是指$k$类在$R_i$中的比例</li>
<li>$Gini$值越低，划分质量越高，所以我们也要最小化$Gini$函数的加权和</li>
</ul>
</li>
<li>我们也可以使用$Entropy$<ul>
<li>$\operatorname{Entropy}\left(i \mid j, t_j\right)&#x3D;-\sum_k P\left(k \mid R_i\right) \log _2 P\left(k \mid R_i\right)$<ul>
<li>也就是说$j$分类器下，以$t_j$为阈值，$i$区域的熵是$i$区域内所有$k$个class的占比乘上其占比对2求对数的和的倒数</li>
</ul>
</li>
<li>当然，我们要最小化$\min_{j,t_j}\left{\frac{N_1}N\operatorname{Entropy}(1|j,t_j)+\frac{N_2}N\operatorname{Entropy}(2|j,t_j)\right}$<ul>
<li>含义也与之前类似，就是通过某种方式找到一个最优分类器和分类阈值</li>
</ul>
</li>
</ul>
</li>
</ul>
<h5 id="Stopping-Condition"><a href="#Stopping-Condition" class="headerlink" title="Stopping Condition"></a>Stopping Condition</h5><ul>
<li>如果不加以限制，决策树会不断进行划分，直到每个叶子都只包含一个节点为止，这也达成了训练集上的100%准确率<ul>
<li>为了避免以上情况，我们提出一些合理的停止策略</li>
<li>例如，我们可以限制决策树的深度</li>
<li>当某一区域内全都为同一种类时停止划分</li>
<li>对每一区域内的数量设置下限</li>
<li>对总叶子数量设置上限</li>
<li>计算划分收益，对收益设置下限<ul>
<li>注，收益一般可表示为</li>
<li>$\mathrm{Gain}(R)&#x3D;\Delta(R)&#x3D;m(R)-\frac{N_1}Nm(R_1)-\frac{N_2}Nm(R_2)$</li>
</ul>
</li>
</ul>
</li>
</ul>
<h5 id="For-Regression"><a href="#For-Regression" class="headerlink" title="For Regression"></a>For Regression</h5><blockquote>
<p>当然，决策树也可以用来做回归问题</p>
</blockquote>
<ul>
<li>同样是对于问题空间进行分割，分割后的每一块区域取其中元素的平均值作为回归决策树对于这一块数据的预测值</li>
<li>这一次，我们需要最小化的是区域内的点的值和我们预测的值（也就是我们框起来的区域的点的平均值）的差距，我们一般采用以下计算方法</li>
<li>$$\operatorname{argmin}_{j,t_j}\left{\frac{N_1}NMSE(R_1)+\frac{N_2}NMSE(R_2)\right}$$</li>
<li>或者</li>
<li>$$\text{ argmin}_{j,t_j}\left{\frac{N_1}NVar(y|x\in R_1)+\frac{N_2}NVar(y|x\in R_1)\right}$$</li>
<li>其实，如果我们将预测值选为区域内$y$的均值的话，二者结果是一样的</li>
</ul>
<h5 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h5><blockquote>
<p>说一下有关名字的由来，其实是Bootstrap aggregating的缩写，意思分别是“自助采样”和 “聚合”</p>
</blockquote>
<ul>
<li>较深的或者较大的决策树常常会过拟合，在新的数据集上有较大的方差</li>
<li>一般来说，我们可以采取以下方法<ul>
<li>对训练数据采样，对于每一组采样（一般来说，一个自助样本（有放回抽样的样本）大约包含原始数据集中约63.2%的唯一实例），训练一个决策树<ul>
<li>这里解释一下采样的相关问题</li>
<li>采样与数据集大小完全一样，但由于是有放回采样，所以依据公式计算，每个数据点不被选中的概率连续乘以自身N次，即$(1-\frac{1}{N})^N$ 趋近于 $e^{-1}$，也就是说，抽到与原始数据集一样大的话，包含着六成多一点的无重复数据</li>
</ul>
</li>
<li>之后对于一个给定的输入，我们将其放入所有的决策树并将结果取平均作为输出</li>
</ul>
</li>
<li>当然，这样做也存在着缺点，我们在提高模型表现的同时，损失了模型的可解释性</li>
</ul>
<h5 id="Random-forest"><a href="#Random-forest" class="headerlink" title="Random forest"></a>Random forest</h5><ul>
<li>为什么需要Random Forest<ul>
<li>bagging得到的树都是在同一个数据集中抽样得到的数据上训练的，而且采用的都是相同的贪心策略，这往往会导致生成的树在结构上非常相似，以至于会拥有极其类似的分布</li>
<li>当我们有B棵树，两两相关系数为$\rho$，自身方差为$\sigma^2$时，他们的均值的方差为$\rho\sigma^2+\frac{1-\rho}B\sigma^2$</li>
<li>从这个式子可以看出，即使在bagging算法中，我们使用了再大的B，也无法消除前一项的影响，而假设树之间的相关性较高，则优化程度有限，本质上是因为，决策树不独立</li>
</ul>
</li>
<li>每棵树每步分裂限制特征集，限制每一步的“视角”，在限制的特征集中选择最优的特征和阈值，最终融合不同视角进行投票<ul>
<li>实操上，我们在每一步分裂时，随机选择一组特征，在其中选择最优的特征</li>
<li>补充说明一些可以调整的超参数<ul>
<li>每次随机挑选的特征数量</li>
<li>随机森林中树的总数</li>
<li>叶结点的最小规模</li>
</ul>
</li>
</ul>
</li>
<li>如何进一步调整随机森林<ul>
<li>交叉验证<ul>
<li>随机森林天然可以交叉验证，因为我们使用一部分数据来构建决策树，剩下的数据就可以用来评估</li>
</ul>
</li>
<li>随机排列特征数据<ul>
<li>我们想要评估一个特征在整个随机森林中的重要性，我们可以对袋外数据中的某一个特征进行随机排列，然后测试决策树因为特征被随机排列而造成的计算准确度下降情况</li>
<li>对随机森林中所有的树做如上操作后，计算平均情况，即可得到该特征在整个随机森林中的平均重要性</li>
</ul>
</li>
</ul>
</li>
<li>随机森林仍然不是完美的算法<ul>
<li>如果特征的数量有很多，但是有用的特征很少的时候，随机森林的效果可能会很差，因为我们随机选择特征很容易选中很多没用的特征而漏选有用特征，构建出来的树很可能完全无法有效学习数据格式</li>
<li>树的数量极大时，又会回到树相关性提高，方差变大的问题</li>
</ul>
</li>
</ul>
<h5 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h5><blockquote>
<p>The strength of week learners</p>
</blockquote>
<ul>
<li>原理是，首先使用week classifier进行学习，之后依据预测结果，给出residual。下一个week classifier对特征和残差进行学习，得到一个新的预测结果，和residual得出下一个residual，反复进行，并在最后以一定参数融合所有的week classifier</li>
</ul>
<h5 id="GBoosting"><a href="#GBoosting" class="headerlink" title="GBoosting"></a>GBoosting</h5><ul>
<li>XGBoost是GBoosting的一种特定实现</li>
</ul>
<h5 id="K-nearest-neighbourhood"><a href="#K-nearest-neighbourhood" class="headerlink" title="K-nearest neighbourhood"></a>K-nearest neighbourhood</h5><ul>
<li>关键思想：一个样本的类别可以通过其K个最近邻居的类别来决定</li>
<li>也可以固定邻居数、固定搜索半径等</li>
<li>也可以使用soft boundary，距离点越近权重越高</li>
<li>但同时，测算点的距离对于计算机是较为繁琐的</li>
</ul>
<h2 id="Unsupervised-Learning"><a href="#Unsupervised-Learning" class="headerlink" title="Unsupervised Learning"></a>Unsupervised Learning</h2><h3 id="Clustering"><a href="#Clustering" class="headerlink" title="Clustering"></a>Clustering</h3><h4 id="K-means（no-label）"><a href="#K-means（no-label）" class="headerlink" title="K-means（no label）"></a>K-means（no label）</h4><ul>
<li>首先在数据点中，随机选K个点作为聚类中心</li>
<li>将每个数据点分配到距离它最近的聚类中心</li>
<li>对于每个聚类，计算其所有数据点的平均位置，更新聚类中心的位置</li>
<li>直达聚类中心不发生变化或者达到预定的迭代次数</li>
</ul>
<h4 id="Hierarchical-clustering（层次聚类）"><a href="#Hierarchical-clustering（层次聚类）" class="headerlink" title="Hierarchical clustering（层次聚类）"></a>Hierarchical clustering（层次聚类）</h4><ul>
<li>Hierarchical agglomerative clustering（层次凝聚聚类）<ul>
<li>初始状态下，每个数据点都被认为是一个单独的聚类。</li>
<li>计算每对聚类之间的相似度或距离。</li>
<li>根据相似度或距离的度量规则，选择最相似的两个聚类进行合并。</li>
<li>合并后的聚类形成一个新的聚类，替代原来的两个聚类。</li>
<li>重复步骤，直到所有数据点都合并为一个聚类或达到预设的聚类数量。</li>
</ul>
</li>
<li>Divisive clustering（分裂聚类）<ul>
<li>初始状态下，所有数据点都被归为一个聚类。</li>
<li>计算当前聚类中的数据点的相似度或距离。</li>
<li>根据相似度或距离的度量规则，选择一个聚类进行分裂。</li>
<li>分裂所选的聚类，将其划分为两个或多个子聚类。</li>
<li>重复步骤2-4，直到每个数据点都成为一个单独的聚类或达到预设的聚类数量。</li>
</ul>
</li>
</ul>
<h3 id="Big-Data-Clustering"><a href="#Big-Data-Clustering" class="headerlink" title="Big Data Clustering"></a>Big Data Clustering</h3><ul>
<li><h4 id="BFR（人名算法）"><a href="#BFR（人名算法）" class="headerlink" title="BFR（人名算法）"></a>BFR（人名算法）</h4><ul>
<li>初始阶段，将整个数据集分为几个较小的子集。</li>
<li>在每个子集上应用一个聚类算法，如K-means或层次聚类。</li>
<li>分析每个子集的聚类结果，根据一些评估指标（如聚类质量、聚类数量等）来决定是否需要进一步划分或合并聚类。</li>
<li>如果需要划分，将子集进一步划分为更小的子集，并重复步骤2-3。<br>  如果需要合并，将具有相似性质的聚类合并在一起，并重复步骤2-3。</li>
</ul>
</li>
<li>Clustering using representatives (CURE)</li>
</ul>
<h2 id="Support-vector"><a href="#Support-vector" class="headerlink" title="Support vector"></a>Support vector</h2><blockquote>
<p>核心逻辑，尝试最大化两个类别中的间隔，同时确保所有的数据点都被正确分类<br>使用Lagrange对偶性，我们可以将这个问题转化为对偶问题<br>一旦我们解决了对偶问题，我们可以使用互补松弛性来确定哪些数据点是支持向量，从而确定决策边界</p>
</blockquote>
<ul>
<li>Support vector regression<ul>
<li>让马路盖住所有点，但是越窄越好</li>
</ul>
</li>
<li>Support vector clustering</li>
<li>Transudative support vector machine</li>
</ul>
<h3 id="Kernel-方法"><a href="#Kernel-方法" class="headerlink" title="Kernel 方法"></a>Kernel 方法</h3><blockquote>
<p>将点向高维映射，有时可以使数据点明显分开</p>
</blockquote>
<h2 id="Learning-with-Probabilistic-Graphic-Model"><a href="#Learning-with-Probabilistic-Graphic-Model" class="headerlink" title="Learning with Probabilistic Graphic Model"></a>Learning with Probabilistic Graphic Model</h2><h3 id="Directed-graphs-Baysian-network"><a href="#Directed-graphs-Baysian-network" class="headerlink" title="Directed graphs (Baysian network)"></a>Directed graphs (Baysian network)</h3><ul>
<li>逻辑是，对于多个事件，建立很多小的表，以避免建立所有情况合成的大表</li>
<li>从独立到条件独立</li>
</ul>
<h3 id="Undirected-graphs-Markov-random-field"><a href="#Undirected-graphs-Markov-random-field" class="headerlink" title="Undirected graphs (Markov random field)"></a>Undirected graphs (Markov random field)</h3><h2 id="Reinforcement-learning"><a href="#Reinforcement-learning" class="headerlink" title="Reinforcement learning"></a>Reinforcement learning</h2><h3 id="马尔可夫奖励过程（MRP-Markov-reward-process）"><a href="#马尔可夫奖励过程（MRP-Markov-reward-process）" class="headerlink" title="马尔可夫奖励过程（MRP Markov reward process）"></a>马尔可夫奖励过程（MRP Markov reward process）</h3><ul>
<li>首先进行基本定义，一般可以定义为$\langle S,P,R,\gamma \rangle$<ul>
<li>$S$是一个有限的状态集合</li>
<li>$P$是转移概率矩阵，$P_{ss’}$记录了从$s$状态出发，到达$s’$状态的概率</li>
<li>$R$是奖励函数<ul>
<li>$R_s$是当前在$s$状态下，下一时刻能获得的奖励期望</li>
</ul>
</li>
<li>$\gamma$是折现参数<ul>
<li>对远期能获得的奖励乘系数“折现”</li>
</ul>
</li>
</ul>
</li>
<li>关键方程<ul>
<li>位置价值函数$v(s) &#x3D;\mathbb{E}[G_t|S_t&#x3D;s]$ 也就是现在在状态$s$，之后总的收益期望</li>
<li>也可以递归定义如下：$$v(s)&#x3D;\mathbb{E}[R_t|S_t&#x3D;s]+\gamma\sum_{s^{\prime}}v(s^{\prime})P[S_{t+1}&#x3D;s^{\prime}|S_t&#x3D;s]$$</li>
<li>第一项是在$t$时刻处于状态$s$时，$t+1$时刻获得的即时$Reward$的期望，后面的累加项统计了下一步的所有可能，并将它们的价值函数折现求和。</li>
<li>这里的$\gamma$是折现函数</li>
</ul>
</li>
<li>两种计算$v$的方法<ul>
<li>矩阵计算<ul>
<li>$v&#x3D;R+\gamma pv$ </li>
<li>故$v&#x3D;(I-\gamma\mathcal{P})^{-1}\mathcal{R}$</li>
</ul>
</li>
<li>动态规划<ul>
<li>在收敛之前，依据公式反复迭代<ul>
<li>$v^{(k)}(s)&#x3D;R(s)+\gamma\sum_{s’\in S}P(s’|s)v^{(k-1)}\left(s’\right)$</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="马尔可夫决策过程-Markov-decision-process（MDP）"><a href="#马尔可夫决策过程-Markov-decision-process（MDP）" class="headerlink" title="马尔可夫决策过程 Markov decision process（MDP）"></a>马尔可夫决策过程 Markov decision process（MDP）</h3><blockquote>
<p>在MRP基础上引入了决策过程</p>
</blockquote>
<ul>
<li>同样可给出定义$\langle S,A,P,R,\gamma \rangle$<ul>
<li>补充定义了$A$，$A$是有限的行为的集合，例如平面游戏中的上下左右之类的</li>
</ul>
</li>
<li>策略(policy)<ul>
<li>策略就是在给定状态下，决策的分布，一般记作$\pi$，定义是$\left.\pi(a|s)&#x3D;\mathbb{P}\left[A_{t}&#x3D;a\right|S_{t}&#x3D;s\right]$</li>
</ul>
</li>
<li>在引入了决策过程后，状态价值函数发生了改变，因为此时其同样与policy相关<ul>
<li>定义$v_{\pi}(s)&#x3D;\mathbb{E}<em>{\pi}[G</em>{t}|S_{t}&#x3D;s]$ ，这是新的状态价值函数</li>
<li>定义$q_\pi(s,a)&#x3D;\mathbb{E}_\pi[G_t|S_t&#x3D;s,A_t&#x3D;\alpha]$ ，这被称作决策价值函数<ul>
<li>含义是：在时间$t$处于状态$s$时，做出决策$\alpha$且之后遵循policy $\pi$的预期收益</li>
</ul>
</li>
<li>在如上定义之后，我们可以把$v$的公式改写为<ul>
<li>$v_\pi(s)&#x3D;\mathbb{E}<em>\pi[G_t|S_t&#x3D;s]&#x3D;\sum</em>{a\in\mathcal{A}}\mathbb{E}_\pi[G_t,A_t&#x3D;a|S_t&#x3D;s]$<ul>
<li>穷举所有的决策求和</li>
</ul>
</li>
<li>$&#x3D;\sum_{a\in\mathcal{A}}\mathbb{E}<em>{\pi}[G</em>{t}|S_{t}&#x3D;s,A_{t}&#x3D;a]\mathbb{P}[A_{t}&#x3D;a|S_{t}&#x3D;s]$</li>
<li>$&#x3D;\sum_{a\in\mathcal{A}}q_{\pi}(s,a)\pi(a|s)$ <ul>
<li>当然，我们也可以将$q_{\pi}$定义为递归形式</li>
<li>${\mathcal R}<em>{s}^{a}+\gamma\sum</em>{\forall s\prime}v_{\pi}(s^{\prime}){\mathcal P}_{ss^{\prime}}^{a}$<ul>
<li>思路与之前类似</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>小网格世界示例<ul>
<li>![[Pasted image 20231107164046.png]]<ul>
<li>agent服从全局随机策略，即上下左右均为0.25概率</li>
<li>如果操作走出了网格，则状态不变</li>
<li>多次迭代直到收敛，我们就对每个点建立了$v_{\pi(random)}$ 但是，基于这种策略的答案，是最好的吗？<ul>
<li>显然不是，需要优化</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="MDP-Policy-Iteration"><a href="#MDP-Policy-Iteration" class="headerlink" title="MDP: Policy Iteration"></a>MDP: Policy Iteration</h3><ul>
<li>主体思想是，对于每一种策略$\pi$，先计算$v_{\pi}$再将$greedy(\pi)$作为下一个策略，反复进行策略改进，直到收敛为止<ul>
<li>一般可以用$\pi(a|s)&#x3D;\frac1{A(s)}$进行初始化（$A(s)$指的是$s$状态下，可执行的决策总数）</li>
<li>伪代码表示策略更新<ul>
<li>$\pi^{<em>}(a|s)&#x3D;\operatorname</em>{argmax}<em>{\mathrm{a}}q</em>{\pi}(s,a)$</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="MDP-Value-Iteration"><a href="#MDP-Value-Iteration" class="headerlink" title="MDP: Value Iteration"></a>MDP: Value Iteration</h3><ul>
<li>主体思想，不依赖更新Policy进而更新$v$，而是直接在每次迭代中更新$v$，以此隐性地更新策略</li>
<li>具体来说，每次更新$v$的方法是，选取能最大化该轮$v(s)$的动作$a$，那其实也就是选取了最优决策，感觉是上一种方法的升级版</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sunyrain.github.io/2023/09/19/2023-09-19/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="whilesunny">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="whilesunny">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/09/19/2023-09-19/" class="post-title-link" itemprop="url">日记9-19</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-09-19 07:58:25" itemprop="dateCreated datePublished" datetime="2023-09-19T07:58:25+08:00">2023-09-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-09-20 19:57:26" itemprop="dateModified" datetime="2023-09-20T19:57:26+08:00">2023-09-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Life/" itemprop="url" rel="index"><span itemprop="name">Life</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>美好的一天开始啦！</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2023/09/19/2023-09-19/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sunyrain.github.io/2023/09/19/xian-dai-sheng-wu-xue-dao-lun/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="whilesunny">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="whilesunny">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/09/19/xian-dai-sheng-wu-xue-dao-lun/" class="post-title-link" itemprop="url">现代生物学导论</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-09-19 07:49:10" itemprop="dateCreated datePublished" datetime="2023-09-19T07:49:10+08:00">2023-09-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-11-07 08:31:18" itemprop="dateModified" datetime="2023-11-07T08:31:18+08:00">2023-11-07</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AF%BE%E7%A8%8B/" itemprop="url" rel="index"><span itemprop="name">课程</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <span id="more"></span>
<h2 id="DNA与蛋白质的结构与功能"><a href="#DNA与蛋白质的结构与功能" class="headerlink" title="DNA与蛋白质的结构与功能"></a>DNA与蛋白质的结构与功能</h2><h3 id="生物系统的弱化学作用"><a href="#生物系统的弱化学作用" class="headerlink" title="生物系统的弱化学作用"></a>生物系统的弱化学作用</h3><ul>
<li>强弱化学作用<ul>
<li>强化学作用<ul>
<li>生理温度下稳定</li>
<li>包括所有的化学键</li>
</ul>
</li>
<li>弱化学作用<ul>
<li>生物体内不断生成和断裂</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="DNA的结构和功能"><a href="#DNA的结构和功能" class="headerlink" title="DNA的结构和功能"></a>DNA的结构和功能</h3><ul>
<li>DNA的化学组成<ul>
<li>磷酸、五碳糖、含氮碱基</li>
</ul>
</li>
<li>DNA的功能<ul>
<li>多样性、存储遗传信息、可复制、稳定</li>
</ul>
</li>
<li>DNA的一级结构（存储遗传信息）<ul>
<li>多聚核苷酸单链</li>
<li>一级结构的应用<ul>
<li>寻找生物间演化关系<ul>
<li>人类（23对）、黑猩猩（及后均为24对）、大猩猩、红毛猩猩</li>
<li>假说：人类染色体在演化过程中发生了融合<ul>
<li>可能更长</li>
<li>可能含有不止一处着丝粒、端粒</li>
<li>比较序列等</li>
<li>……</li>
</ul>
</li>
</ul>
</li>
<li>DNA指纹鉴定</li>
</ul>
</li>
</ul>
</li>
<li>DNA的二级结构</li>
<li>DNA的三级结构</li>
</ul>
<h3 id="蛋白质的结构与功能"><a href="#蛋白质的结构与功能" class="headerlink" title="蛋白质的结构与功能"></a>蛋白质的结构与功能</h3><ul>
<li>蛋白质的四级结构</li>
<li>蛋白质功能</li>
<li>蛋白质折叠</li>
<li>分子伴侣蛋白<ul>
<li>hsp60工作机制</li>
</ul>
</li>
<li>蛋白质折叠与疾病</li>
<li>结构与功能的关系<ul>
<li>例如：DNA聚合酶</li>
</ul>
</li>
</ul>
<h2 id="细胞和癌"><a href="#细胞和癌" class="headerlink" title="细胞和癌"></a>细胞和癌</h2><h3 id="细胞通信"><a href="#细胞通信" class="headerlink" title="细胞通信"></a>细胞通信</h3><p>（单细胞生物之间存在细胞通讯）</p>
<h4 id="细胞通讯的种类"><a href="#细胞通讯的种类" class="headerlink" title="细胞通讯的种类"></a>细胞通讯的种类</h4><ul>
<li>旁分泌信号</li>
<li>内分泌信号</li>
</ul>
<h4 id="细胞通信的过程"><a href="#细胞通信的过程" class="headerlink" title="细胞通信的过程"></a>细胞通信的过程</h4><ul>
<li>信号接受<ul>
<li>信号分子</li>
<li>受体<ul>
<li>细胞表面受体<ul>
<li>G蛋白耦合受体</li>
<li>受体络氨酸激酶</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>信号转导<ul>
<li>磷酸化级联</li>
<li>第二信使<ul>
<li>非蛋白类小分子</li>
<li>cAMP环腺苷酸</li>
<li>cGMP环鸟苷酸</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="细胞周期"><a href="#细胞周期" class="headerlink" title="细胞周期"></a>细胞周期</h3><h4 id="调控细胞周期的分子机制"><a href="#调控细胞周期的分子机制" class="headerlink" title="调控细胞周期的分子机制"></a>调控细胞周期的分子机制</h4><ul>
<li>周期素和蛋白激酶</li>
<li>生长因子</li>
</ul>
<h3 id="细胞凋亡"><a href="#细胞凋亡" class="headerlink" title="细胞凋亡"></a>细胞凋亡</h3><ul>
<li>凋亡过程<ul>
<li>细胞收缩、染色体凝结</li>
<li>膜起泡</li>
<li>细胞核塌陷</li>
<li>凋亡体形成</li>
<li>凋亡小体裂解</li>
</ul>
</li>
<li>三种信号通路<ul>
<li>线粒体通路</li>
<li>死亡受体通路</li>
<li>内质网通路</li>
</ul>
</li>
</ul>
<h3 id="细胞自噬"><a href="#细胞自噬" class="headerlink" title="细胞自噬"></a>细胞自噬</h3><ul>
<li>自噬过程<ul>
<li>自噬泡形成</li>
<li>自噬体形成</li>
<li>自噬体和溶酶体融合</li>
<li>自噬溶酶体形成</li>
<li>降解和再吸收</li>
</ul>
</li>
<li>细胞自噬与疾病</li>
</ul>
<h3 id="液-液相分离"><a href="#液-液相分离" class="headerlink" title="液-液相分离"></a>液-液相分离</h3><ul>
<li>无膜细胞器</li>
</ul>
<h4 id="DNA和基因"><a href="#DNA和基因" class="headerlink" title="DNA和基因"></a>DNA和基因</h4><ul>
<li>基因<ul>
<li>控制性状</li>
</ul>
</li>
<li>基因的构成<ul>
<li>调控区域<ul>
<li>指导基因是否能够产生蛋白</li>
</ul>
</li>
<li>启动子<ul>
<li>和转录酶结合的序列</li>
</ul>
</li>
<li>编码区域</li>
<li>断裂基因<ul>
<li>细菌基因：连续</li>
<li>动物基因：断裂</li>
</ul>
</li>
<li>原核基因</li>
<li>真核基因<ul>
<li>产生蛋白质的序列<ul>
<li>内含子&amp;外显子</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>染色质与染色体<ul>
<li>从DNA到染色质</li>
</ul>
</li>
<li>遗传物质保证稳定机制<ul>
<li>DNA精确复制<ul>
<li>碱基配对</li>
<li>DNA聚合酶的校正</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="遗传密码的特点"><a href="#遗传密码的特点" class="headerlink" title="遗传密码的特点"></a>遗传密码的特点</h3><ul>
<li>多个遗传密码对应同一个氨基酸</li>
</ul>
<h4 id="调控从基因到蛋白质的过程"><a href="#调控从基因到蛋白质的过程" class="headerlink" title="调控从基因到蛋白质的过程"></a>调控从基因到蛋白质的过程</h4><ul>
<li>对环境刺激做出应答</li>
<li>发育</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sunyrain.github.io/2023/09/18/ji-hua/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="whilesunny">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="whilesunny">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/09/18/ji-hua/" class="post-title-link" itemprop="url">计划</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2023-09-18 20:45:41 / 修改时间：20:49:09" itemprop="dateCreated datePublished" datetime="2023-09-18T20:45:41+08:00">2023-09-18</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%94%9F%E6%B4%BB/" itemprop="url" rel="index"><span itemprop="name">生活</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li>21:00 跑步</li>
<li>21:30 - 22:10视唱练耳+弹琴</li>
<li>22:10 - 22:50画画</li>
<li>22:50 - 23:00收拾收拾准备睡觉</li>
<li>（找时间复习！！！）</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sunyrain.github.io/2023/09/18/2023-09-18/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="whilesunny">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="whilesunny">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/09/18/2023-09-18/" class="post-title-link" itemprop="url">日记9-18</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2023-09-18 11:42:14 / 修改时间：20:45:34" itemprop="dateCreated datePublished" datetime="2023-09-18T11:42:14+08:00">2023-09-18</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Life/" itemprop="url" rel="index"><span itemprop="name">Life</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>开局啥都听不懂，忽闻改培养方案，寄。</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2023/09/18/2023-09-18/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sunyrain.github.io/2023/09/18/cai-liao-fen-xi-yu-biao-zheng/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="whilesunny">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="whilesunny">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/09/18/cai-liao-fen-xi-yu-biao-zheng/" class="post-title-link" itemprop="url">材料分析与表征 9.18</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-09-18 09:35:33" itemprop="dateCreated datePublished" datetime="2023-09-18T09:35:33+08:00">2023-09-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-10-30 12:15:34" itemprop="dateModified" datetime="2023-10-30T12:15:34+08:00">2023-10-30</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AF%BE%E7%A8%8B/" itemprop="url" rel="index"><span itemprop="name">课程</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <span id="more"></span>
<ul>
<li>课程详细信息<ul>
<li>期末考试70%、课程展示20%、考勤作业10%</li>
</ul>
</li>
</ul>
<h3 id="X射线衍射技术-X-Ray-Diffraction"><a href="#X射线衍射技术-X-Ray-Diffraction" class="headerlink" title="X射线衍射技术(X-Ray Diffraction)"></a>X射线衍射技术(X-Ray Diffraction)</h3><ul>
<li>X光的发现 1895.11.8 伦琴</li>
<li>肉眼不可见、使铂氯化钡发光、使照相底板感光、气体电离、杀伤生物细胞</li>
</ul>
<h3 id="微观结构的研究方法"><a href="#微观结构的研究方法" class="headerlink" title="微观结构的研究方法"></a>微观结构的研究方法</h3><ul>
<li>仪器极限分辨率 $\lambda$&#x2F;2 （远场光学）</li>
</ul>
<h3 id="X光的本质"><a href="#X光的本质" class="headerlink" title="X光的本质"></a>X光的本质</h3><ul>
<li>波长介于紫外线和 $\gamma$ 射线之间，约为0.01~100埃</li>
<li>长波长——软X射线 短波长——硬X射线</li>
</ul>
<h3 id="X射线的应用与发展"><a href="#X射线的应用与发展" class="headerlink" title="X射线的应用与发展"></a>X射线的应用与发展</h3><h3 id="X射线的性质"><a href="#X射线的性质" class="headerlink" title="X射线的性质"></a>X射线的性质</h3><h3 id="X射线的产生"><a href="#X射线的产生" class="headerlink" title="X射线的产生"></a>X射线的产生</h3><ul>
<li>高速运动的带电粒子的运动遇到障碍被减速时便产生X射线</li>
<li>从X射线管角度理解<ul>
<li>对绕成螺旋型的钨丝通电加热至白热，放出热辐射电子</li>
<li>电子在数万伏管内高压电场的作用下轰击靶材产生X射线</li>
</ul>
</li>
</ul>
<h3 id="X射线谱"><a href="#X射线谱" class="headerlink" title="X射线谱"></a>X射线谱</h3><ul>
<li>连续X射线谱，有公式$eV &#x3D; h\nu <em>{max}&#x3D;\frac{hc}{\lambda</em>{0}}$ </li>
<li>经验规律，连续谱中强度最大处的波长记为$\lambda_{m}$ 则一般有$\lambda_{m}&#x3D;1.5\lambda_{0}$</li>
<li>电流决定了热辐射电子的多少，电压决定了热辐射电子的强度</li>
</ul>
<h3 id="例题"><a href="#例题" class="headerlink" title="例题"></a>例题</h3><ul>
<li>已知$Cu-K_a$线波长，计算铜原子$2p$和$1s$能级间的能量差<ul>
<li>解题方法，首先明确从$2p$到$1s$属于从$L$层跃迁到$K$层，也即$K_a$线</li>
<li>故直接利用波长与能量关系计算</li>
</ul>
</li>
</ul>
<h3 id="X射线与物质的相互作用"><a href="#X射线与物质的相互作用" class="headerlink" title="X射线与物质的相互作用"></a>X射线与物质的相互作用</h3><h3 id="X射线衰减规律"><a href="#X射线衰减规律" class="headerlink" title="X射线衰减规律"></a>X射线衰减规律</h3><ul>
<li>吸收的不连续性</li>
<li>吸收限的利用<ul>
<li>靶材（Target Material）：</li>
<li>靶材通常是一个坚固的材料，如金属，用于产生X射线。当高速电子束撞击靶材时，与原子相互作用，产生X射线辐射。我们要尽量选择波长略长于试样吸收限的靶材，这样不会有K系荧光辐射，同时也不会被试样吸收太多。</li>
<li>滤片（Filter）：</li>
<li>滤片是放置在X射线束路径上的材料，通常由金属或其他适当的材料制成。滤片的主要作用是改变或调整X射线的能量谱。通过选择不同材料的滤片，可以过滤掉低能量的X射线，使得只有特定能量范围内的X射线通过</li>
<li>试样（Sample）：</li>
<li>试样是要进行X光实验的物质或样品。当X射线穿过试样时，它会与试样中的原子相互作用，产生一系列特定能量的X射线散射或吸收。通过分析这些散射或吸收事件，可以获得有关试样的信息，例如其成分、结构或厚度等</li>
</ul>
</li>
</ul>
<h3 id="X光的探测与防护"><a href="#X光的探测与防护" class="headerlink" title="X光的探测与防护"></a>X光的探测与防护</h3><h2 id="晶体学基础"><a href="#晶体学基础" class="headerlink" title="晶体学基础"></a>晶体学基础</h2><h3 id="晶体结构"><a href="#晶体结构" class="headerlink" title="晶体结构"></a>晶体结构</h3><ul>
<li><p>赤平极射投影</p>
<ul>
<li>方位角 $\phi$包含该点的子午面与$0°$子午面的夹角</li>
<li>极距角 $\rho$该点与北极点的夹角</li>
<li>赤平投影图上点距离圆心的距离与方位角有关，基圆与极距角有关<br>  重点（吴氏网、标准点阵、倒易点阵）</li>
</ul>
</li>
<li><p>吴氏网</p>
<ul>
<li>吴氏网只能水平上走格子，如果想在竖直上走格子，需要旋转吴氏网，然后再所有的点一起水平上走格子<br> 对于任意可微的对称性，一定存在一个相应的守恒流</li>
</ul>
</li>
<li><p>倒易点阵</p>
<ul>
<li><p>对于一个给定基矢的正点阵，必有倒易点阵与之相对应，关系为<br>$$a^{*}&#x3D;\frac{b×c}{v}$$<br>此处$v$为正点阵的体积	</p>
</li>
<li><p>有关正点阵和倒易点阵，相关的符号标识如下</p>
<ul>
<li>晶面指数$(hkl),(uvw)^{*}$</li>
<li>晶向指数$[uvw],[hkl]^{*}$</li>
<li>面间距$d_{hkl},d_{uvw}^{*}$</li>
<li>晶向或阵矢$r&#x3D;ua+vb+wc,g^{<em>}&#x3D;ha^</em>+kb^*+lc^*$</li>
<li>晶向长度或阵矢大小$r_{uvw},g_{hkl}$</li>
<li>结点位置$uvw,hkl$</li>
</ul>
</li>
<li><p>倒易点阵晶向垂直于正点阵同名晶面，反之亦然</p>
</li>
<li><p>正点阵的面间距是同名倒易矢量长度的倒数</p>
<p>$$|g_{hkl}|^2&#x3D; \frac1{d_{hkl}^2}&#x3D;(h\boldsymbol{a}^*+k\boldsymbol{b}^*+l\boldsymbol{c}^*)\bullet(h\boldsymbol{a}^*+k\boldsymbol{b}^*+l\boldsymbol{c}^*)\&#x3D; h^2(a^*)^2+k^2(b^*)^2+l^2(c^*)^2\+2kl\boldsymbol{b}^<em>\boldsymbol{c}^</em>\boldsymbol{c}^<em>cos\boldsymbol{a}^</em>+2lh\boldsymbol{c}^<em>\boldsymbol{a}^</em>cos\boldsymbol{\beta}^*+2h\boldsymbol{k}a^<em>\boldsymbol{b}^</em>cos\boldsymbol{\gamma}^* $$</p>
<ul>
<li>立方晶系<ul>
<li>$d_{hkl}&#x3D;\frac{a}{\sqrt{h^2+k^2+l^2}}$</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="阶段作业"><a href="#阶段作业" class="headerlink" title="阶段作业"></a>阶段作业</h3><ul>
<li>P81-82 T 15 16 22 24</li>
</ul>
<h2 id="X射线与材料的散射、干涉与衍射"><a href="#X射线与材料的散射、干涉与衍射" class="headerlink" title="X射线与材料的散射、干涉与衍射"></a>X射线与材料的散射、干涉与衍射</h2><h3 id="散射"><a href="#散射" class="headerlink" title="散射"></a>散射</h3><ul>
<li><p>电子的散射，静电相互作用等</p>
</li>
<li><p>X射线的散射，与物质的基本单元发生作用</p>
</li>
<li><p>单电子对X射线的散射</p>
<ul>
<li>相干散射<ul>
<li>相干散射是衍射的基础，从波动性的角度出发，X射线是电磁波，其照射在自由电子上时，交变电场就会强迫电子作频率相同的振动，发射X射线。电子发出的X射线为散射线，与入射线波长相同、相位滞后恒定，故可以发生干涉。</li>
<li>平面偏振光相干散射</li>
<li>非平面偏振光相干散射<ul>
<li>原子中只需要考虑电子散射</li>
</ul>
</li>
</ul>
</li>
<li>非相干散射</li>
</ul>
</li>
<li><p>散射线的干涉</p>
<ul>
<li>相位差与反射矢量<ul>
<li>相位差满足$$\phi &#x3D; 2\pi \frac{-S_{0}·r+S·r }{\lambda}$$其中$S_0$为入射线上的单位矢量，$S$为反射线上的单位矢量</li>
<li>记 $s&#x3D;\frac{S-S_0}{\lambda}\quad s$为散射矢量，其大小为$\frac{2sin\theta}{\lambda}$，引入散射矢量后，上式可化作$\phi &#x3D;2\pi s·r$</li>
</ul>
</li>
</ul>
</li>
<li><p>原子对X射线的散射</p>
<ul>
<li>单电子原子的散射<ul>
<li>原子中一个电子的散射因子$$f(s) &#x3D; \int_v \rho(r)e^{i2\pi s·r}dv$$</li>
<li>电子的相干强度为$I_{相干}&#x3D;f^{2}(s)I_{电子}$</li>
</ul>
</li>
<li>多电子原子的散射<ul>
<li>假设原子的总电荷密度为各个电子电荷密度之和</li>
</ul>
</li>
</ul>
</li>
<li><p>晶胞的散射</p>
</li>
<li><p>小晶体的衍射</p>
<ul>
<li><p>小晶体的衍射强度</p>
<ul>
<li><p>小晶体的衍射线振幅</p>
<p>$$<br>A_\text{ 晶体 }{ ( s ) }&#x3D;\sum_{m&#x3D;0}^{N_a-1}\sum_{m&#x3D;0}^{N_b-1}\sum_{p&#x3D;0}^{N_c-1}F\left(s\right)\mathrm{e}^{\mathrm{i}2\pi\mathbf{s}\cdot\mathbf{R}_{mnp}}<br>$$</p>
<p>因其中的结构因子与晶胞的位置无关, 从而有<br>$$<br>A_\text{ 晶体 }{ ( s ) }&#x3D;F\left(s\right)\sum_{m&#x3D;0}^{N_a-1}\sum_{m&#x3D;0}^{N_b-1}\sum_{p&#x3D;0}^{N_c-1}\mathrm{e}^{\mathrm{i}2\pi\mathbf{s}\cdot\mathbf{R}<em>{mnp}}<br>$$<br>于是, 晶体的衍射线强度为<br>$$<br>I</em>{\text {晶体 }}(s)&#x3D;|F(s)|^2\left|\sum_{m n p}^N \mathrm{e}^{\mathrm{i} 2 \pi s \cdot \boldsymbol{R}<em>{m p p}}\right|^2 I</em>{\text {电子 }}<br>$$<br>定义<br>$$<br>L(s) \equiv\left|\sum_{m n p}^N \mathrm{e}^{\mathrm{i} 2 \pi s \cdot \boldsymbol{R}<em>{\operatorname{mmp}}}\right|^2<br>$$<br>由于它表示的是晶体散射线的干涉结果, 故称为晶体的干涉函数, 或劳厄函数, 衍射线强度可以简写成<br>$$<br>I</em>{\text {晶体 }}(s)&#x3D;|F(s)|^2 L(s) I_{\text {电子 }}<br>$$</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="衍射线的强度分析"><a href="#衍射线的强度分析" class="headerlink" title="衍射线的强度分析"></a>衍射线的强度分析</h2><h2 id="多晶体衍射信息的获取方法"><a href="#多晶体衍射信息的获取方法" class="headerlink" title="多晶体衍射信息的获取方法"></a>多晶体衍射信息的获取方法</h2><h3 id="德拜法"><a href="#德拜法" class="headerlink" title="德拜法"></a>德拜法</h3><ul>
<li>德拜照片的计算与标定<ul>
<li><img src="https://raw.githubusercontent.com/sunyrain/ForPicGo/main/img/image-20231009103514509.png" alt="image-20231009103514509" style="zoom:50%;" />
</li>
<li><p>圆弧之间的对应的顶角为4$\theta$</p>
</li>
<li><img src="https://raw.githubusercontent.com/sunyrain/ForPicGo/main/img/image-20231009104249654.png" alt="image-20231009104249654" style="zoom:50%;" />
</li>
<li><p>此处采用的角度标准为（deg）</p>
</li>
<li><img src="https://raw.githubusercontent.com/sunyrain/ForPicGo/main/img/image-20231009104341784.png" alt="image-20231009104341784" style="zoom:50%;" />
</li>
<li><p>考虑布拉格公式$d&#x3D;\frac{\lambda}{2sin\theta}$和晶面间距计算公式$d_{hkl}&#x3D;\frac{a}{\sqrt{h^2+k^2+l^2}}$</p>
</li>
<li><p>得$$\sin^2\theta&#x3D;\frac{\lambda^2}{4a^2}(h^2+k^2+l^2)$$</p>
</li>
<li><p>令$\frac{\lambda^{2}}{4a^2}&#x3D;K$并设$m$为干涉指数的平方和，即$$m&#x3D;h^2+k^2+l^2$$于是$sin^2\theta &#x3D; Km$</p>
</li>
<li><p>计算出$K$和每条德拜线的$sin^2\theta$并计算出对应的m值（$m$均为正整数）然后依据衍射线条在晶系中的出现顺序判断</p>
</li>
</ul>
</li>
</ul>
<h3 id="衍射仪法"><a href="#衍射仪法" class="headerlink" title="衍射仪法"></a>衍射仪法</h3><h3 id="衍射材料的获得"><a href="#衍射材料的获得" class="headerlink" title="衍射材料的获得"></a>衍射材料的获得</h3><h4 id="试样制备要求"><a href="#试样制备要求" class="headerlink" title="试样制备要求"></a>试样制备要求</h4><ul>
<li>晶粒大小</li>
<li>试样大小厚度和质量</li>
<li>避免产生择优取向</li>
</ul>
<h4 id="衍射全图的获得"><a href="#衍射全图的获得" class="headerlink" title="衍射全图的获得"></a>衍射全图的获得</h4><h4 id="单峰测试"><a href="#单峰测试" class="headerlink" title="单峰测试"></a>单峰测试</h4><h4 id="衍射信息的获取"><a href="#衍射信息的获取" class="headerlink" title="衍射信息的获取"></a>衍射信息的获取</h4><h4 id="衍射线的线形分析"><a href="#衍射线的线形分析" class="headerlink" title="衍射线的线形分析"></a>衍射线的线形分析</h4><h2 id="单晶体衍射信息的获取方法"><a href="#单晶体衍射信息的获取方法" class="headerlink" title="单晶体衍射信息的获取方法"></a>单晶体衍射信息的获取方法</h2><h3 id="劳埃法"><a href="#劳埃法" class="headerlink" title="劳埃法"></a>劳埃法</h3><ul>
<li>特征：使用连续的X射线谱照射固定不动的单晶体</li>
</ul>
<h2 id="X射线衍射的应用"><a href="#X射线衍射的应用" class="headerlink" title="X射线衍射的应用"></a>X射线衍射的应用</h2><h3 id="物相分析"><a href="#物相分析" class="headerlink" title="物相分析"></a>物相分析</h3><h4 id="定性相分析"><a href="#定性相分析" class="headerlink" title="定性相分析"></a>定性相分析</h4><h4 id="定量相分析"><a href="#定量相分析" class="headerlink" title="定量相分析"></a>定量相分析</h4><ul>
<li><p>PDF卡片</p>
</li>
<li><p>基础：物质的衍射强度与物质参与衍射的体积成正比<br>$$<br>I&#x3D;\frac{I_0 \lambda^3}{32 \pi R v_0^2}\left(\frac{e^2}{m c^2}\right)^2 \frac{1+\cos ^2 2 \theta}{\sin ^2 \theta \cos \theta} F^2 P V \mathrm{e}^{-2 M} A(\theta)<br>$$</p>
<ul>
<li>对于粉末衍射仪法，$A(\theta)&#x3D;1&#x2F;2\mu$</li>
</ul>
</li>
<li><p>举例来说，两相体系下<br>$$<br>\begin{aligned}<br>&amp; I_\alpha&#x3D;\frac{I_0 \lambda^3}{32 \pi R v_\alpha^2}\left(\frac{e^2}{m c^2}\right)^2\left(\frac{1+\cos ^2 2 \theta}{\sin ^2 \theta \cos \theta} F^2 P \mathrm{e}^{-2 M}\right)_\alpha \frac{V_\alpha}{2 \mu} \<br>&amp; I_\beta&#x3D;\frac{I_0 \lambda^3}{32 \pi R v_\beta^2}\left(\frac{e^2}{m c^2}\right)^2\left(\frac{1+\cos ^2 2 \theta}{\sin ^2 \theta \cos \theta} F^2 P \mathrm{e}^{-2 M}\right)_\beta \frac{V_\beta}{2 \mu}<br>\end{aligned}<br>$$</p>
<ul>
<li>$\mu$ 是混合物的线吸收系数</li>
<li>前面的部分二者都相同，所以只和$V$有关系</li>
<li>$\mu ^*$是质量吸收系数，为$\mu &#x2F; \rho$</li>
<li>不管什么方法，$\alpha$相衍射强度 $I_{\alpha}&#x3D;K\frac{C_{\alpha}}{\mu}$</li>
</ul>
</li>
<li><p>外标法</p>
<ul>
<li>本质上是<br>  $$<br>  I_\alpha&#x3D;K \frac{w_a}{\rho_\alpha \mu^*}<br>  $$</li>
<li>上式的$\mu ^*$是总质量吸收系数</li>
<li>而对于纯 $\alpha$ 相的试样, 即标样, 其同指数衍射线的强度应为<br>  $$<br>  I_{\alpha_0}&#x3D;K \frac{1}{\rho_\alpha \mu_a^*}<br>  $$</li>
<li>从而, 待测试样中 $\alpha$ 相的衍射强度与 $\alpha$ 相标样的衍射强度的比值为</li>
</ul>
<p>  $$<br>  \frac{I_a}{I_{\alpha_0}}&#x3D;\frac{\mu_a^*}{\mu^*} w_a<br>  $$</p>
<ul>
<li>如果试样仅由 $\alpha 、 \beta$ 两相组成, 则上式可以写成</li>
</ul>
<p>  $$<br>  \frac{I_\alpha}{I_{\alpha_0}}&#x3D;\frac{w_\alpha \mu_\alpha^*}{w_\alpha\left(\mu_\alpha^*-\mu_\beta^<em>\right)+\mu_\beta^</em>}<br>  $$</p>
<ul>
<li>实际使用时，首先要知道是什么和什么的混合，找到工作曲线，之后通过两次实验测定$\frac{I_\alpha}{I_{\alpha_0}}$，在工作表上对应找即知道物质百分比</li>
</ul>
</li>
<li><p>内标法</p>
<ul>
<li>内标法首先向试样中加入标准物，然后让待测相与标准相进行比较，相当于通过加入标准相的方法，知道了$\omega _{s}$ </li>
<li>待测相衍射线强度与标准相衍射线强度之比可以表述为</li>
<li>$$\frac{I^{‘}<em>{a}}{I</em>{s}}&#x3D;K\frac{\omega^{‘}<em>{a}}{\omega</em>{s}}$$</li>
<li>设法得到$K$值即可</li>
</ul>
</li>
</ul>
<h4 id="精确测定点阵常数"><a href="#精确测定点阵常数" class="headerlink" title="精确测定点阵常数"></a>精确测定点阵常数</h4><h2 id="宏观应力分析"><a href="#宏观应力分析" class="headerlink" title="宏观应力分析"></a>宏观应力分析</h2><h3 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h3><p>只要有应力存在就会有应变，，也即晶面间距的变化。X光可以很好地测面间距的变化，所以可以用来测应力。</p>
<h4 id="应力应变关系"><a href="#应力应变关系" class="headerlink" title="应力应变关系"></a>应力应变关系</h4><ul>
<li><p>考虑受轴向拉力$F_x$的截面为A的棒</p>
<ul>
<li>胡克定律指出$\epsilon_x &#x3D; \frac{\sigma_x}{E}$</li>
<li>轴向拉伸，垂直于轴的面也会发生形变</li>
<li>$$-\epsilon_y &#x3D; -\epsilon_z &#x3D; \nu \epsilon_x &#x3D; \frac{\nu \sigma_x}{E}$$<ul>
<li>其中$\nu$是泊松比</li>
</ul>
</li>
</ul>
</li>
<li><p>考虑微变形情况下，主应力和主应变的广义胡克定律为</p>
<ul>
<li>$\epsilon_1 &#x3D; \frac{1}{E}[\sigma_1 - \nu(\sigma_2+\sigma_3)]$<ul>
<li>（$cyc$）</li>
</ul>
</li>
</ul>
</li>
<li><p>任意一个方向（注意应力是一个张量）</p>
<p>$$ \left{\begin{array}{l}<br>\sigma_{\phi \psi}&#x3D;\alpha_1^2 \sigma_1+\alpha_2^2 \sigma_2+\alpha_3^2 \sigma_3 \<br>\varepsilon_{\phi \psi}&#x3D;\alpha_1^2 \varepsilon_1+\alpha_2^2 \varepsilon_2+\alpha_3^2 \varepsilon_3<br>\end{array}\right.$$</p>
</li>
<li><p>其中$$\begin{aligned}<br>&amp; \alpha_1&#x3D;\sin \psi \cos \phi \<br>&amp; \alpha_2&#x3D;\sin \psi \sin \phi \<br>&amp; \alpha_3&#x3D;\cos \psi<br>\end{aligned} $$</p>
</li>
<li><p>广义胡克定律<br>$$\left{\begin{array}{l}\varepsilon_1&#x3D;\frac{1}{E}\left[\sigma_1-\nu\left(\sigma_2+\sigma_3\right)\right] \ \varepsilon_2&#x3D;\frac{1}{E}\left[\sigma_2-\nu\left(\sigma_1+\sigma_3\right)\right] \ \varepsilon_3&#x3D;\frac{1}{E}\left[\sigma_3-\nu\left(\sigma_1+\sigma_2\right)\right]\end{array}\right.$$</p>
</li>
</ul>
<h4 id="X射线衍射方法测定应力的原理"><a href="#X射线衍射方法测定应力的原理" class="headerlink" title="X射线衍射方法测定应力的原理"></a>X射线衍射方法测定应力的原理</h4><p>对于一般的金属材料，X射线的穿透能力很低，所以仅能测定表面层的应力。又垂直于表面层的应力的总和为0.也即$\sigma_3 &#x3D; 0$</p>
<ul>
<li><p>广义胡克定律在此前提下简化为：</p>
</li>
<li><p>$$<br>\left{\begin{array}{l}<br>\varepsilon_1&#x3D;\frac{1}{E}\left(\sigma_1-\nu \sigma_2\right) \<br>\varepsilon_2&#x3D;\frac{1}{E}\left(\sigma_2-\nu \sigma_1\right) \<br>\varepsilon_3&#x3D;-\frac{\nu}{E}\left(\sigma_1+\sigma_2\right)<br>\end{array}\right.<br>$$</p>
</li>
<li><p>带入$\varepsilon_{\phi \psi}&#x3D;\alpha_1^2 \varepsilon_1+\alpha_2^2 \varepsilon_2+\alpha_3^2 \varepsilon_3$化简即得到：</p>
</li>
<li><p>$$<br>\varepsilon_{\phi \psi}&#x3D;\frac{1+\nu}{E} \sigma_\phi \sin ^2 \psi-\frac{\nu}{E}\left(\sigma_1+\sigma_2\right)<br>$$</p>
<ul>
<li>注意$\sigma_\phi &#x3D; cos^2\phi \sigma_1 +sin^2 \phi \sigma_2$</li>
</ul>
<p>将上式对 $\sin ^2 \psi$ 求导, 就可以解出表面上任一方向上的应力 $\sigma_\phi$, 有：<br>$$<br>\sigma_\phi&#x3D;\frac{E}{1+\nu} \frac{\partial \varepsilon_{\phi \psi}}{\partial \sin ^2 \psi}<br>$$</p>
</li>
</ul>
<h3 id="衍射仪法测定宏观应力"><a href="#衍射仪法测定宏观应力" class="headerlink" title="衍射仪法测定宏观应力"></a>衍射仪法测定宏观应力</h3><h2 id="微晶尺寸和微观应力"><a href="#微晶尺寸和微观应力" class="headerlink" title="微晶尺寸和微观应力"></a>微晶尺寸和微观应力</h2><h4 id="微晶尺寸的测定"><a href="#微晶尺寸的测定" class="headerlink" title="微晶尺寸的测定"></a>微晶尺寸的测定</h4><h4 id="微观应力的测定"><a href="#微观应力的测定" class="headerlink" title="微观应力的测定"></a>微观应力的测定</h4><h2 id="织构的测定"><a href="#织构的测定" class="headerlink" title="织构的测定"></a>织构的测定</h2><h3 id="织构的分类"><a href="#织构的分类" class="headerlink" title="织构的分类"></a>织构的分类</h3><ul>
<li>丝织构<ul>
<li>丝织构的晶体学特点是晶粒的某一个或者某几个晶向倾向于平行试样的某一特定方向，一般沿丝轴方向或生长方向</li>
</ul>
</li>
<li>板织构<ul>
<li>板织构的晶体学特征是各晶粒的某一个或几个晶面平行于试样的某一特定面(如轧面),一个或几个晶向平行于试样的某一特定方向(如轧向)。</li>
</ul>
</li>
</ul>
<h3 id="织构的表示方法"><a href="#织构的表示方法" class="headerlink" title="织构的表示方法"></a>织构的表示方法</h3><ul>
<li>正级图</li>
<li>反级图</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sunyrain.github.io/2023/09/17/2023-09-17/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="whilesunny">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="whilesunny">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/09/17/2023-09-17/" class="post-title-link" itemprop="url">日记9-17</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-09-17 15:03:49" itemprop="dateCreated datePublished" datetime="2023-09-17T15:03:49+08:00">2023-09-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-09-18 19:17:53" itemprop="dateModified" datetime="2023-09-18T19:17:53+08:00">2023-09-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Life/" itemprop="url" rel="index"><span itemprop="name">Life</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>第一次用Obsidian，感觉还挺好诶，不过笔记的精髓是文字。</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2023/09/17/2023-09-17/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sunyrain.github.io/2023/09/12/du-re-bian-ma-xiang-liang-hua-ji-biao-qian-huan-yuan/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="whilesunny">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="whilesunny">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/09/12/du-re-bian-ma-xiang-liang-hua-ji-biao-qian-huan-yuan/" class="post-title-link" itemprop="url">one-hot编码向量化及还原</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-09-12 23:01:06" itemprop="dateCreated datePublished" datetime="2023-09-12T23:01:06+08:00">2023-09-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-09-18 14:44:33" itemprop="dateModified" datetime="2023-09-18T14:44:33+08:00">2023-09-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Tricks/" itemprop="url" rel="index"><span itemprop="name">Tricks</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>打kaggle遇到的一些细节</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2023/09/12/du-re-bian-ma-xiang-liang-hua-ji-biao-qian-huan-yuan/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sunyrain.github.io/2023/09/12/he-sheng/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="whilesunny">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="whilesunny">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/09/12/he-sheng/" class="post-title-link" itemprop="url">和声学学习</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-09-12 14:05:42" itemprop="dateCreated datePublished" datetime="2023-09-12T14:05:42+08:00">2023-09-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-09-18 19:18:59" itemprop="dateModified" datetime="2023-09-18T19:18:59+08:00">2023-09-18</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Parallel-Life/" itemprop="url" rel="index"><span itemprop="name">Parallel Life</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="绪论"><a href="#绪论" class="headerlink" title="绪论"></a>绪论</h1><h2 id="和弦（和弦音）"><a href="#和弦（和弦音）" class="headerlink" title="和弦（和弦音）"></a>和弦（和弦音）</h2><h4 id="和声、和音、和弦"><a href="#和声、和音、和弦" class="headerlink" title="和声、和音、和弦"></a>和声、和音、和弦</h4><ul>
<li><p>和声学：研究和音的结构以及它们如何连接</p>
</li>
<li><p>和弦中各音的名称</p>
<ul>
<li>和弦按三度关系排列后，最低的音为根音，向上依次为三、五、七、九……名称不随排列位置改变而改变。</li>
</ul>
</li>
<li><p>和弦音</p>
</li>
<li><p>和弦外音</p>
<ul>
<li>延留音，出现在强拍或次强拍，使得音高与自己接近的和弦音延迟出现。除了延留音，其他的和弦外音都出现在弱拍上。</li>
<li>经过音，和弦音上下级之间的过渡。</li>
<li>辅助音，和弦音与其重复音之间的连接</li>
<li>先现音，后一和弦音在弱拍上提前出现</li>
</ul>
</li>
<li><p>非三度结构的和音</p>
</li>
</ul>
<h1 id="第一章"><a href="#第一章" class="headerlink" title="第一章"></a>第一章</h1><h3 id="大三和弦与小三和弦、四部和声"><a href="#大三和弦与小三和弦、四部和声" class="headerlink" title="大三和弦与小三和弦、四部和声"></a>大三和弦与小三和弦、四部和声</h3><ul>
<li><p>定义</p>
<ul>
<li>大三和弦，大三度+小三度（基于根音的大三度+纯五度）</li>
<li>小三和弦，小三度+大三度（基于根音的小三度+纯五度）</li>
<li>增减（两个大三度、两个小三度）</li>
</ul>
</li>
<li><p>四部和声</p>
<ul>
<li>四声部，高音、中音、次中音、低音</li>
</ul>
</li>
<li><p>三和弦的旋律位置</p>
</li>
</ul>
<h1 id="第二章"><a href="#第二章" class="headerlink" title="第二章"></a>第二章</h1><h3 id="正三和弦的功能体系"><a href="#正三和弦的功能体系" class="headerlink" title="正三和弦的功能体系"></a>正三和弦的功能体系</h3><ul>
<li>主、副、属</li>
<li>建立在音阶的Ⅰ级，也就是主音上的三和弦叫做主三和弦，在大调中用T表示，小调中用t表示</li>
<li>进行、进行的公式<ul>
<li>和弦的连续构成了和声进行，最简单的和声进行逻辑基础就是</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sunyrain.github.io/2023/07/06/deep-learning-with-pytorch/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="whilesunny">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="whilesunny">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/07/06/deep-learning-with-pytorch/" class="post-title-link" itemprop="url">未命名</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-07-06 15:21:25" itemprop="dateCreated datePublished" datetime="2023-07-06T15:21:25+08:00">2023-07-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-09-18 16:27:45" itemprop="dateModified" datetime="2023-09-18T16:27:45+08:00">2023-09-18</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Deep-Learning-with-Pytorch"><a href="#Deep-Learning-with-Pytorch" class="headerlink" title="Deep Learning with Pytorch"></a>Deep Learning with Pytorch</h1><h2 id="Chapter1"><a href="#Chapter1" class="headerlink" title="Chapter1"></a>Chapter1</h2><h2 id="Chapter2-P1"><a href="#Chapter2-P1" class="headerlink" title="Chapter2 P1"></a>Chapter2 P1</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#引入pytorch包</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment">#查看版本</span></span><br><span class="line">torch.version.__version__</span><br><span class="line"><span class="comment">#定义全一张量</span></span><br><span class="line">a=torch.ones(<span class="number">3</span>,<span class="number">3</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查询显卡状态</span></span><br><span class="line">torch.cuda.is_available()</span><br><span class="line"><span class="comment">#将张量转移至显卡进行计算,利用tensor的.to方法</span></span><br><span class="line">a=a.to(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line"><span class="comment">#如果在不同设备进行计算，则会报错</span></span><br></pre></td></tr></table></figure>

<h2 id="Chapter2-P2"><a href="#Chapter2-P2" class="headerlink" title="Chapter2 P2"></a>Chapter2 P2</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#在out的第2个（参数1代表第2个）维度选取最大值，函数返回值有两个，分别为最大值和最大值位置，不需要的话以_占位即可</span></span><br><span class="line">_, index = torch.<span class="built_in">max</span>(out,<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<h2 id="Chapter3-P1"><a href="#Chapter3-P1" class="headerlink" title="Chapter3 P1"></a>Chapter3 P1</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#python自带的列表</span></span><br><span class="line">a = [<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>]</span><br><span class="line"><span class="comment">#torch中的张量,out为tensor([1.,1.,1.])</span></span><br><span class="line">a = torch.ones(<span class="number">3</span>)</span><br><span class="line"><span class="comment">#按下标访问，例如a[2],则返回tensor(1.),仍然是张量,取float后值为1.0，也即</span></span><br><span class="line"><span class="built_in">float</span>(a[<span class="number">1</span>])=<span class="number">1.0</span></span><br><span class="line"><span class="comment">#tensor也可按下标修改,如</span></span><br><span class="line">a[<span class="number">2</span>]=<span class="number">2.0</span></span><br><span class="line"><span class="comment">#全零tensor,如torch.zeros(6)</span></span><br><span class="line"><span class="comment">#直接定义tensor</span></span><br><span class="line">points=torch.tensor([<span class="number">4.</span>,<span class="number">1.</span>,<span class="number">5.</span>,<span class="number">3.</span>,<span class="number">2.</span>,<span class="number">1.</span>])</span><br><span class="line"><span class="comment">#有关高维张量</span></span><br><span class="line">point = torch.tensor([<span class="number">4.0</span>,<span class="number">1.0</span>],[<span class="number">5</span>,<span class="number">0</span>,<span class="number">3.0</span>].[<span class="number">2.0</span>,<span class="number">1.0</span>])</span><br><span class="line"><span class="comment">#返回形状</span></span><br><span class="line">points.shape</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sunyrain.github.io/2023/06/17/2023-06-17/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="whilesunny">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="whilesunny">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/06/17/2023-06-17/" class="post-title-link" itemprop="url">日记6-17</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-06-17 22:40:04" itemprop="dateCreated datePublished" datetime="2023-06-17T22:40:04+08:00">2023-06-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-09-21 12:47:47" itemprop="dateModified" datetime="2023-09-21T12:47:47+08:00">2023-09-21</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%94%9F%E6%B4%BB/" itemprop="url" rel="index"><span itemprop="name">生活</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>平凡的很累的一天，拿什么来记住呢？</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2023/06/17/2023-06-17/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/4/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><span class="page-number current">5</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/6/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">
      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">whilesunny</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">71</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">whilesunny</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        
<div class="busuanzi-count">
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/pjax/pjax.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  




  
<script src="/js/local-search.js"></script>













    <div id="pjax">
  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

    </div>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/shizuku.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":0.7}});</script></body>
</html>
